{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AONFxhXBZSA3"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLQ32A_ypgDE"
      },
      "outputs": [],
      "source": [
        "# conda create -n fs python==3.9\n",
        "# conda activate fs\n",
        "# pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUnyUXPOUnA",
        "outputId": "f5aa8cf1-5e1d-4911-db22-68d3edb73f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2a_mTOytXY8",
        "outputId": "89a18c2b-89c8-4164-c7d3-76e5bf46d586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW1shZ-NQbOt",
        "outputId": "8d3c1cd0-51b1-4ccc-bbf3-65723d2fecb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr  7 10:27:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckU16WReZT57"
      },
      "source": [
        "## FairSeq\n",
        "\n",
        "Installation: https://github.com/facebookresearch/fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIxHMl1hYdHH",
        "outputId": "438b429c-7dcc-4a00-f074-1b275b50d87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34540, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 34540 (delta 0), reused 3 (delta 0), pack-reused 34534\u001b[K\n",
            "Receiving objects: 100% (34540/34540), 24.05 MiB | 19.99 MiB/s, done.\n",
            "Resolving deltas: 100% (25086/25086), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/iaramer/fairseq-hc.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0FlswhdY_nD",
        "outputId": "be42427f-3952-4fc1-e1d5-f25a814bdf16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fairseq  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlPpcPL7Y-8-",
        "outputId": "25bc7a84-bcd8-44ee-b635-f45f57bda60b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ]
        }
      ],
      "source": [
        "%cd fairseq-hc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQOlhZTbZCZw",
        "outputId": "2e000139-fd23-4de7-bad0-e85158eddf4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (4.65.0)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (0.29.34)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (23.0)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (2022.10.31)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.6/269.6 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (1.22.4)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.2) (2.0.0+cu118)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.5.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.10.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (16.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fairseq==0.12.2) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fairseq==0.12.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fairseq==0.12.2) (1.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp39-cp39-linux_x86_64.whl size=9192 sha256=365c71de72af41554000b6d4d2708b05210f946cdf6603ffde40e2f212004220\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8_qmolu5/wheels/52/da/57/31b8a8f767e4d044de3fbb1f204d0f1547e8c6e0b171e56bba\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=b965960cf03b7b4f4e23d0209b054697fe162624d9e40e71d3599ffee19a5bad\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.3 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjw1vuARtp42",
        "outputId": "22394d57-c0ff-4779-ab4f-277cdf53b39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ifsJ7YNZV8_"
      },
      "source": [
        "## NVIDIA Apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopd4qf3Zdi3",
        "outputId": "0e7eb517-71f0-477b-d949-de759334e94d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZhhVxm6ZYMy",
        "outputId": "363fc1fc-837f-406f-e2b0-82544536a2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 10919, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 10919 (delta 15), reused 19 (delta 2), pack-reused 10874\u001b[K\n",
            "Receiving objects: 100% (10919/10919), 15.24 MiB | 19.76 MiB/s, done.\n",
            "Resolving deltas: 100% (7557/7557), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYEAYGwbZgmY",
        "outputId": "25ccc2a5-47cc-4b08-e9ab-dd3714dc9a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq/apex\n"
          ]
        }
      ],
      "source": [
        "%cd apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZZW-litVvQz"
      },
      "outputs": [],
      "source": [
        "# Remove check_cuda_torch_binary_vs_bare_metal(CUDA_HOME), line 171"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_mVyqePZjPV",
        "outputId": "fac3cc99-cf70-4f60-e6c1-234a0102d558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing pip 22.0.4 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/fairseq/apex\n",
            "  Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.13.1+cu116\n",
            "\n",
            "\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-uc3k3ds9/apex.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.9/dist-packages (from apex==0.1) (23.0)\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Running command Running setup.py install for apex\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.13.1+cu116\n",
            "\n",
            "\n",
            "  Submodule 'apex/contrib/csrc/multihead_attn/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path 'apex/contrib/csrc/multihead_attn/cutlass'\n",
            "  Cloning into '/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass'...\n",
            "  Submodule path 'apex/contrib/csrc/multihead_attn/cutlass': checked out '66d9cddc832c1cdc2b30a8755274f7f74640cfe6'\n",
            "  running install\n",
            "  /usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "    warnings.warn(\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.9\n",
            "  creating build/lib.linux-x86_64-3.9/apex\n",
            "  copying apex/__init__.py -> build/lib.linux-x86_64-3.9/apex\n",
            "  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-3.9/apex\n",
            "  creating build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.9/apex/amp\n",
            "  creating build/lib.linux-x86_64-3.9/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.9/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.9/apex/normalization\n",
            "  creating build/lib.linux-x86_64-3.9/apex/fused_dense\n",
            "  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-3.9/apex/fused_dense\n",
            "  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-3.9/apex/fused_dense\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/enums.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/utils.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-3.9/apex/transformer\n",
            "  creating build/lib.linux-x86_64-3.9/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.9/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.9/apex/multi_tensor_apply\n",
            "  creating build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.9/apex/optimizers\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib\n",
            "  creating build/lib.linux-x86_64-3.9/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.9/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.9/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.9/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.9/apex/fp16_utils\n",
            "  creating build/lib.linux-x86_64-3.9/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.9/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.9/apex/mlp\n",
            "  creating build/lib.linux-x86_64-3.9/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.9/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.9/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.9/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib.linux-x86_64-3.9/apex/RNN\n",
            "  creating build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.9/apex/parallel\n",
            "  creating build/lib.linux-x86_64-3.9/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.9/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.9/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.9/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.9/apex/amp/lists\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/amp\n",
            "  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/amp\n",
            "  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-3.9/apex/transformer/amp\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/layers\n",
            "  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/layers\n",
            "  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-3.9/apex/transformer/layers\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-3.9/apex/transformer/testing\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/_data\n",
            "  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/_data\n",
            "  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-3.9/apex/transformer/_data\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/functional\n",
            "  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/functional\n",
            "  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-3.9/apex/transformer/functional\n",
            "  creating build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.9/apex/contrib/groupbn\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-3.9/apex/contrib/index_mul_2d\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-3.9/apex/contrib/focal_loss\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.9/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-3.9/apex/contrib/transducer\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-3.9/apex/contrib/clip_grad\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.9/apex/contrib/layer_norm\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-3.9/apex/contrib/conv_bias_relu\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.9/apex/contrib/xentropy\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test\n",
            "  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.9/apex/contrib/optimizers\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.9/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-3.9/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.9/apex/contrib/bottleneck\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-3.9/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-3.9/apex/contrib/peer_memory\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-3.9/apex/contrib/cudnn_gbn\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.9/apex/contrib/fmha\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/index_mul_2d\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/focal_loss\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/transducer\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/clip_grad\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/layer_norm\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/conv_bias_relu\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/xentropy\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/bottleneck\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/peer_memory\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/cudnn_gbn\n",
            "  creating build/lib.linux-x86_64-3.9/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-3.9/apex/contrib/test/fmha\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.8) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:397: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "  building 'apex_C' extension\n",
            "  creating build/temp.linux-x86_64-3.9\n",
            "  creating build/temp.linux-x86_64-3.9/csrc\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/include/python3.9 -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.9/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/flatten_unflatten.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/apex_C.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'amp_C' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.9/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_l2norm_kernel_mp.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_l2norm_scale_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_lamb_mp.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_kernel_mp.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_l2norm_scale_kernel.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_mp.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.9/csrc/multi_tensor_sgd_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/amp_C.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'syncbn' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.9/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/welford.cu -o build/temp.linux-x86_64-3.9/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/syncbn.o build/temp.linux-x86_64-3.9/csrc/welford.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/syncbn.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'fused_layer_norm_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.9/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.9/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.9/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/fused_layer_norm_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'mlp_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.9/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "  csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "     57 |   for (int i = 0; i < num_layers; i++) {\n",
            "        |                   ~~^~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "        |                                                                             ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/mlp.cpp:65:86: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
            "        |                                                                                      ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
            "        |                                                           ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:69:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |                                                      ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "  csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "    115 |   for (int i = 0; i < num_layers; i++) {\n",
            "        |                   ~~^~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "    120 |   for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                   ~~^~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "        |                                                                   ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:124:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |                                                      ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                                   ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                                   ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                                   ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/mlp.o build/temp.linux-x86_64-3.9/csrc/mlp_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/mlp_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'fused_dense_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/fused_dense.cpp -o build/temp.linux-x86_64-3.9/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     30 |   auto out = at::empty({batch_size, out_features}, input.type());\n",
            "        |                                                               ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                                       ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:35:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |                                                  ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n",
            "        |                                                                     ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     68 |   auto d_bias = at::empty({out_features}, input.type());\n",
            "        |                                                      ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "        |                                                                  ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                                       ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:75:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |                                                  ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                                      ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                                      ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n",
            "        |                                                                   ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                                       ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:113:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |                                                  ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
            "        |                                                                         ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
            "        |                                                                          ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n",
            "        |                                                          ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    152 |   auto d_bias2 = at::empty({out_features}, input.type());\n",
            "        |                                                       ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "        |                                                                  ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                                        ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                                       ^\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:159:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |                                                  ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:238:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    238 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "    216 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.9/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.9/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:241:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    241 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                                                        ^\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n",
            "    268 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:23: note: declared here\n",
            "    132 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:263:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    263 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:264:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    264 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "    162 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:244:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
            "    244 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:97:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     97 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:265:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
            "    265 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:269:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
            "    269 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/fused_dense_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/fused_dense.o build/temp.linux-x86_64-3.9/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/fused_dense_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.9/csrc/megatron\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/megatron/scaled_upper_triang_masked_softmax.o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/scaled_upper_triang_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'generic_scaled_masked_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/generic_scaled_masked_softmax.cpp -o build/temp.linux-x86_64-3.9/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/megatron/generic_scaled_masked_softmax.o build/temp.linux-x86_64-3.9/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/generic_scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'scaled_masked_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_masked_softmax.cpp -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/megatron/scaled_masked_softmax.o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'scaled_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_softmax.cpp -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/scaled_softmax_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/megatron/scaled_softmax.o build/temp.linux-x86_64-3.9/csrc/megatron/scaled_softmax_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/scaled_softmax_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'fused_weight_gradient_mlp_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/fused_weight_gradient_dense.cpp -o build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c csrc/megatron/fused_weight_gradient_dense_cuda.cu -o build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense.o build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o build/temp.linux-x86_64-3.9/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/fused_weight_gradient_mlp_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'xentropy_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.9/apex\n",
            "  creating build/temp.linux-x86_64-3.9/apex/contrib\n",
            "  creating build/temp.linux-x86_64-3.9/apex/contrib/csrc\n",
            "  creating build/temp.linux-x86_64-3.9/apex/contrib/csrc/xentropy\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/xentropy/interface.cpp -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/xentropy/interface.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=xentropy_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/xentropy/xentropy_kernel.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/xentropy/xentropy_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=xentropy_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/apex/contrib/csrc/xentropy/interface.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/xentropy/xentropy_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/xentropy_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'fused_adam_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.9/apex/contrib/csrc/optimizers\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/optimizers/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/optimizers/fused_adam_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/csrc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/apex/contrib/csrc/optimizers/fused_adam_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/fused_adam_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "  building 'fast_multihead_attn' extension\n",
            "  creating build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(29): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(54): warning #550-D: variable \"softmax_success\" was set but never used\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(89): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(29): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(54): warning #550-D: variable \"softmax_success\" was set but never used\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(89): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(29): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(54): warning #550-D: variable \"softmax_success\" was set but never used\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(89): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(29): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(54): warning #550-D: variable \"softmax_success\" was set but never used\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(89): warning #177-D: variable \"dropout_elems\" was declared but never referenced\n",
            "\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/multihead_attn_frontend.cpp -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/multihead_attn_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(251): warning #191-D: type qualifier is meaningless on cast type\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/softmax.cuh(2058): warning #177-D: variable \"flag_vec4\" was declared but never referenced\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool <unnamed>::masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, <unnamed>::masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  (2350): here\n",
            "              instantiation of \"__nv_bool <unnamed>::dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(249): here\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(251): warning #191-D: type qualifier is meaningless on cast type\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/softmax.cuh(2058): warning #177-D: variable \"flag_vec4\" was declared but never referenced\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool <unnamed>::masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, <unnamed>::masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  (2350): here\n",
            "              instantiation of \"__nv_bool <unnamed>::dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(249): here\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(251): warning #191-D: type qualifier is meaningless on cast type\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/softmax.cuh(2058): warning #177-D: variable \"flag_vec4\" was declared but never referenced\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool <unnamed>::masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, <unnamed>::masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  (2350): here\n",
            "              instantiation of \"__nv_bool <unnamed>::dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(249): here\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(251): warning #191-D: type qualifier is meaningless on cast type\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/softmax.cuh(2058): warning #177-D: variable \"flag_vec4\" was declared but never referenced\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool <unnamed>::masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, <unnamed>::masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  (2350): here\n",
            "              instantiation of \"__nv_bool <unnamed>::dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(249): here\n",
            "\n",
            "  apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(251): warning #191-D: type qualifier is meaningless on cast type\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/include/ -I/content/fairseq/apex/apex/contrib/csrc/multihead_attn/cutlass/tools/util/include -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.cu -o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/multihead_attn_frontend.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.o build/temp.linux-x86_64-3.9/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/fast_multihead_attn.cpython-39-x86_64-linux-gnu.so\n",
            "  running install_lib\n",
            "  copying build/lib.linux-x86_64-3.9/fused_dense_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/syncbn.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/scaled_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/mlp_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/amp_C.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/generic_scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/scaled_upper_triang_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/apex_C.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex\n",
            "  copying build/lib.linux-x86_64-3.9/apex/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/amp.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/opt.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/_amp_state.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/frontend.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/rnn_compat.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/scaler.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/_initialize.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/wrap.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/handle.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/compat.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/lists/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.9/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.9/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.9/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/utils.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/amp/__version__.py -> /usr/local/lib/python3.9/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/_autocast_utils.py -> /usr/local/lib/python3.9/dist-packages/apex\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/normalization\n",
            "  copying build/lib.linux-x86_64-3.9/apex/normalization/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/normalization\n",
            "  copying build/lib.linux-x86_64-3.9/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/normalization\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fused_dense/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fused_dense/fused_dense.py -> /usr/local/lib/python3.9/dist-packages/apex/fused_dense\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/mappings.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/random.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/data.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/memory.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/layers.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/cross_entropy.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/tensor_parallel/utils.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/amp/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/amp/grad_scaler.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/microbatches.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/layers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/layers/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/layers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/layers/layer_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/layers\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules/common.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/_timers.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/p2p_communication.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/pipeline_parallel/utils.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/log_util.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/arguments.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/standalone_bert.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/commons.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/global_vars.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/standalone_transformer_lm.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/distributed_test_base.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/testing/standalone_gpt.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/testing\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/_data/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/_data/_batchsampler.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/_data\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/functional/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/functional/fused_softmax.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/enums.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/utils.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/_ucc_util.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/transformer/parallel_state.py -> /usr/local/lib/python3.9/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-3.9/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.9/dist-packages/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-3.9/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/multi_tensor_apply\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_mixed_precision_lamb.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.9/dist-packages/apex/optimizers\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_lib.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/index_mul_2d/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/index_mul_2d/index_mul_2d.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/index_mul_2d\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/focal_loss\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/focal_loss/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/focal_loss\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/focal_loss/focal_loss.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/focal_loss\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/transducer/transducer.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/transducer/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/transducer/_transducer_ref.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/clip_grad\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/clip_grad/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/clip_grad\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/clip_grad/clip_grad.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/clip_grad\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/layer_norm\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/conv_bias_relu/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/conv_bias_relu/conv_bias_relu.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/conv_bias_relu\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/xentropy\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/index_mul_2d/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/index_mul_2d\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/focal_loss\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/focal_loss/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/focal_loss\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/focal_loss/test_focal_loss.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/focal_loss\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/transducer/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/transducer/test_transducer_joint.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/transducer/test_transducer_loss.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/clip_grad\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/clip_grad/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/clip_grad\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/clip_grad/test_clip_grad.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/clip_grad\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/layer_norm/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/layer_norm\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/conv_bias_relu/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/conv_bias_relu\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/xentropy\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/xentropy/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/xentropy\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/xentropy/test_label_smoothing.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/xentropy\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers/test_dist_adam.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/bottleneck/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/bottleneck/test_bottleneck_module.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/bottleneck\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/peer_memory\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/peer_memory/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/peer_memory\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/peer_memory\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/cudnn_gbn/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/cudnn_gbn\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/test/fmha\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/fmha/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/fmha\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/test/fmha/test_fmha.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/test/fmha\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/bottleneck/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/bottleneck/bottleneck.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/bottleneck/halo_exchangers.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/bottleneck/test.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/peer_memory/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/peer_memory/peer_memory.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/cudnn_gbn/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/cudnn_gbn/batch_norm.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/cudnn_gbn\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/fmha/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-3.9/apex/contrib/fmha/fmha.py -> /usr/local/lib/python3.9/dist-packages/apex/contrib/fmha\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.9/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.9/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.9/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.9/dist-packages/apex/fp16_utils\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/mlp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/mlp/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/mlp\n",
            "  copying build/lib.linux-x86_64-3.9/apex/mlp/mlp.py -> /usr/local/lib/python3.9/dist-packages/apex/mlp\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.9/apex/RNN/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.9/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.9/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.9/apex/RNN/cells.py -> /usr/local/lib/python3.9/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.9/apex/RNN/models.py -> /usr/local/lib/python3.9/dist-packages/apex/RNN\n",
            "  creating /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/distributed.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/__init__.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/LARC.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/multiproc.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.9/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.9/fused_adam_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/xentropy_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/fused_layer_norm_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/fused_weight_gradient_mlp_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.9/fast_multihead_attn.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/amp.py to amp.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/opt.py to opt.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/frontend.py to frontend.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/scaler.py to scaler.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/_initialize.py to _initialize.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/wrap.py to wrap.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/handle.py to handle.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/compat.py to compat.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/utils.py to utils.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/amp/__version__.py to __version__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/_autocast_utils.py to _autocast_utils.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/normalization/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fused_dense/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fused_dense/fused_dense.py to fused_dense.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/random.py to random.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/data.py to data.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/memory.py to memory.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/layers.py to layers.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/tensor_parallel/utils.py to utils.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/amp/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/microbatches.py to microbatches.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/layers/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/layers/layer_norm.py to layer_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/pipeline_parallel/utils.py to utils.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/log_util.py to log_util.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/arguments.py to arguments.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/commons.py to commons.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/global_vars.py to global_vars.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/standalone_transformer_lm.py to standalone_transformer_lm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/_data/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/functional/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/enums.py to enums.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/utils.py to utils.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/_ucc_util.py to _ucc_util.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/transformer/parallel_state.py to parallel_state.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py to channel_swap.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/index_mul_2d/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/index_mul_2d/index_mul_2d.py to index_mul_2d.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/focal_loss/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer/transducer.py to transducer.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/transducer/_transducer_ref.py to _transducer_ref.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/clip_grad/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/clip_grad/clip_grad.py to clip_grad.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/index_mul_2d/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/index_mul_2d/test_index_mul_2d.py to test_index_mul_2d.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/focal_loss/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/focal_loss/test_focal_loss.py to test_focal_loss.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer/test_transducer_joint.py to test_transducer_joint.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/transducer/test_transducer_loss.py to test_transducer_loss.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/clip_grad/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/clip_grad/test_clip_grad.py to test_clip_grad.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/layer_norm/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/layer_norm/test_fast_layer_norm.py to test_fast_layer_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/conv_bias_relu/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py to test_conv_bias_relu.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/xentropy/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/xentropy/test_label_smoothing.py to test_label_smoothing.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers/test_dist_adam.py to test_dist_adam.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/optimizers/test_distributed_fused_lamb.py to test_distributed_fused_lamb.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py to test_self_multihead_attn_norm_add.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_self_multihead_attn.py to test_self_multihead_attn.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py to test_mha_fused_softmax.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py to test_fast_self_multihead_attn_bias.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py to test_encdec_multihead_attn.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py to test_encdec_multihead_attn_norm_add.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/bottleneck/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/bottleneck/test_bottleneck_module.py to test_bottleneck_module.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/peer_memory/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py to test_peer_halo_exchange_module.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/cudnn_gbn/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py to test_cudnn_gbn_with_two_gpus.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/fmha/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/test/fmha/test_fmha.py to test_fmha.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/bottleneck/test.py to test.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/cudnn_gbn/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/cudnn_gbn/batch_norm.py to batch_norm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/fmha/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/contrib/fmha/fmha.py to fmha.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/mlp/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/mlp/mlp.py to mlp.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/RNN/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/RNN/cells.py to cells.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/RNN/models.py to models.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/distributed.py to distributed.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/LARC.py to LARC.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-39.pyc\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing requirements to apex.egg-info/requires.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to /usr/local/lib/python3.9/dist-packages/apex-0.1-py3.9.egg-info\n",
            "  running install_scripts\n",
            "  writing list of installed files to '/tmp/pip-record-x1iln258/install-record.txt'\n",
            "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" \\\n",
        "  --global-option=\"--deprecated_fused_adam\" --global-option=\"--xentropy\" \\\n",
        "  --global-option=\"--fast_multihead_attn\" ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD89j7GCbqrr",
        "outputId": "b4a99f64-412d-440e-b972-2f02e46a23ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3deaJeus7a"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "Instructions: https://github.com/facebookresearch/fairseq/blob/main/examples/scaling_nmt/README.md\n",
        "\n",
        "Dataset (replacement): https://huggingface.co/datasets/wmt16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Xeura0yP4F"
      },
      "source": [
        "## PTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrOf2y8Uyeza",
        "outputId": "4827f6d3-b8e6-4a82-d1de-8f9e13693b26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2023-04-01 16:35:56--  https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5101618 (4.9M) [text/plain]\n",
            "Saving to: ‘ptb.train.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  1% 23.7M 0s\n",
            "    50K .......... .......... .......... .......... ..........  2% 27.1M 0s\n",
            "   100K .......... .......... .......... .......... ..........  3%  137M 0s\n",
            "   150K .......... .......... .......... .......... ..........  4% 33.2M 0s\n",
            "   200K .......... .......... .......... .......... ..........  5%  248M 0s\n",
            "   250K .......... .......... .......... .......... ..........  6%  111M 0s\n",
            "   300K .......... .......... .......... .......... ..........  7% 50.9M 0s\n",
            "   350K .......... .......... .......... .......... ..........  8% 49.6M 0s\n",
            "   400K .......... .......... .......... .......... ..........  9% 42.1M 0s\n",
            "   450K .......... .......... .......... .......... .......... 10% 39.7M 0s\n",
            "   500K .......... .......... .......... .......... .......... 11% 47.9M 0s\n",
            "   550K .......... .......... .......... .......... .......... 12% 44.3M 0s\n",
            "   600K .......... .......... .......... .......... .......... 13% 49.6M 0s\n",
            "   650K .......... .......... .......... .......... .......... 14% 49.8M 0s\n",
            "   700K .......... .......... .......... .......... .......... 15% 58.1M 0s\n",
            "   750K .......... .......... .......... .......... .......... 16% 51.9M 0s\n",
            "   800K .......... .......... .......... .......... .......... 17% 47.6M 0s\n",
            "   850K .......... .......... .......... .......... .......... 18% 54.6M 0s\n",
            "   900K .......... .......... .......... .......... .......... 19% 56.0M 0s\n",
            "   950K .......... .......... .......... .......... .......... 20% 55.1M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 21% 47.0M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 22% 58.9M 0s\n",
            "  1100K .......... .......... .......... .......... .......... 23% 57.4M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 24% 56.1M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 25% 49.2M 0s\n",
            "  1250K .......... .......... .......... .......... .......... 26% 55.5M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 27% 61.0M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 28% 58.0M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 29% 73.3M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 30%  281M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 31%  333M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 32%  232M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 33%  254M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 34%  337M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 35%  301M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 36%  325M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 37%  274M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 38% 55.2M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 39% 42.0M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 40% 38.6M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 41% 53.8M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 42% 55.5M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 43% 54.6M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 44% 54.0M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 45% 46.2M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 46% 58.9M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 47% 57.7M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 48% 49.4M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 49% 55.7M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 50% 49.3M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 51% 60.0M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 52% 61.8M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 53% 75.5M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 54%  285M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 55% 75.1M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 56% 49.2M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 57% 53.4M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 58% 55.6M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 59%  150M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 60%  251M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 61%  243M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 62%  242M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 63%  251M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 64%  281M 0s\n",
            "  3200K .......... .......... .......... .......... .......... 65%  274M 0s\n",
            "  3250K .......... .......... .......... .......... .......... 66%  254M 0s\n",
            "  3300K .......... .......... .......... .......... .......... 67% 51.7M 0s\n",
            "  3350K .......... .......... .......... .......... .......... 68% 54.8M 0s\n",
            "  3400K .......... .......... .......... .......... .......... 69% 53.6M 0s\n",
            "  3450K .......... .......... .......... .......... .......... 70% 52.5M 0s\n",
            "  3500K .......... .......... .......... .......... .......... 71% 59.1M 0s\n",
            "  3550K .......... .......... .......... .......... .......... 72% 60.9M 0s\n",
            "  3600K .......... .......... .......... .......... .......... 73% 53.8M 0s\n",
            "  3650K .......... .......... .......... .......... .......... 74% 59.7M 0s\n",
            "  3700K .......... .......... .......... .......... .......... 75% 59.1M 0s\n",
            "  3750K .......... .......... .......... .......... .......... 76% 54.6M 0s\n",
            "  3800K .......... .......... .......... .......... .......... 77% 58.9M 0s\n",
            "  3850K .......... .......... .......... .......... .......... 78% 77.8M 0s\n",
            "  3900K .......... .......... .......... .......... .......... 79%  270M 0s\n",
            "  3950K .......... .......... .......... .......... .......... 80%  256M 0s\n",
            "  4000K .......... .......... .......... .......... .......... 81%  244M 0s\n",
            "  4050K .......... .......... .......... .......... .......... 82%  272M 0s\n",
            "  4100K .......... .......... .......... .......... .......... 83%  239M 0s\n",
            "  4150K .......... .......... .......... .......... .......... 84%  285M 0s\n",
            "  4200K .......... .......... .......... .......... .......... 85%  235M 0s\n",
            "  4250K .......... .......... .......... .......... .......... 86%  266M 0s\n",
            "  4300K .......... .......... .......... .......... .......... 87%  297M 0s\n",
            "  4350K .......... .......... .......... .......... .......... 88%  117M 0s\n",
            "  4400K .......... .......... .......... .......... .......... 89% 64.1M 0s\n",
            "  4450K .......... .......... .......... .......... .......... 90% 61.9M 0s\n",
            "  4500K .......... .......... .......... .......... .......... 91% 56.2M 0s\n",
            "  4550K .......... .......... .......... .......... .......... 92% 65.6M 0s\n",
            "  4600K .......... .......... .......... .......... .......... 93% 63.1M 0s\n",
            "  4650K .......... .......... .......... .......... .......... 94% 65.0M 0s\n",
            "  4700K .......... .......... .......... .......... .......... 95% 60.7M 0s\n",
            "  4750K .......... .......... .......... .......... .......... 96% 56.2M 0s\n",
            "  4800K .......... .......... .......... .......... .......... 97% 64.1M 0s\n",
            "  4850K .......... .......... .......... .......... .......... 98% 63.4M 0s\n",
            "  4900K .......... .......... .......... .......... .......... 99% 66.2M 0s\n",
            "  4950K .......... .......... .......... ..                   100% 51.7M=0.07s\n",
            "\n",
            "2023-04-01 16:35:56 (68.6 MB/s) - ‘ptb.train.txt’ saved [5101618/5101618]\n",
            "\n",
            "--2023-04-01 16:35:56--  https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 399782 (390K) [text/plain]\n",
            "Saving to: ‘ptb.valid.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 12% 52.0M 0s\n",
            "    50K .......... .......... .......... .......... .......... 25% 43.7M 0s\n",
            "   100K .......... .......... .......... .......... .......... 38%  229M 0s\n",
            "   150K .......... .......... .......... .......... .......... 51% 60.8M 0s\n",
            "   200K .......... .......... .......... .......... .......... 64%  206M 0s\n",
            "   250K .......... .......... .......... .......... .......... 76%  241M 0s\n",
            "   300K .......... .......... .......... .......... .......... 89%  227M 0s\n",
            "   350K .......... .......... .......... ..........           100%  249M=0.004s\n",
            "\n",
            "2023-04-01 16:35:57 (98.1 MB/s) - ‘ptb.valid.txt’ saved [399782/399782]\n",
            "\n",
            "--2023-04-01 16:35:57--  https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 449945 (439K) [text/plain]\n",
            "Saving to: ‘ptb.test.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 11% 26.0M 0s\n",
            "    50K .......... .......... .......... .......... .......... 22% 24.1M 0s\n",
            "   100K .......... .......... .......... .......... .......... 34%  101M 0s\n",
            "   150K .......... .......... .......... .......... .......... 45% 31.2M 0s\n",
            "   200K .......... .......... .......... .......... .......... 56%  156M 0s\n",
            "   250K .......... .......... .......... .......... .......... 68%  171M 0s\n",
            "   300K .......... .......... .......... .......... .......... 79%  195M 0s\n",
            "   350K .......... .......... .......... .......... .......... 91% 43.8M 0s\n",
            "   400K .......... .......... .......... .........            100%  216M=0.008s\n",
            "\n",
            "2023-04-01 16:35:57 (53.0 MB/s) - ‘ptb.test.txt’ saved [449945/449945]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "mkdir -p ptb_data\n",
        "cd ptb_data\n",
        "wget https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt\n",
        "wget https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt\n",
        "wget https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt\n",
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y35HsE5Gy6nd",
        "outputId": "ffec4d56-28be-4145-c4fa-0c0ed613c4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fairseq  ptb_data  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FacrOxrdyexM",
        "outputId": "0371d7f5-d3fc-494c-c0d3-6c347c55f188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-01 16:36:01 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang=None, target_lang=None, trainpref='ptb_data/ptb.train.txt', validpref='ptb_data/ptb.valid.txt', testpref='ptb_data/ptb.test.txt', align_suffix=None, destdir='data-bin/ptb', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=20, dict_only=False)\n",
            "2023-04-01 16:36:04 | INFO | fairseq_cli.preprocess | [None] Dictionary: 10008 types\n",
            "2023-04-01 16:36:10 | INFO | fairseq_cli.preprocess | [None] ptb_data/ptb.train.txt: 42068 sents, 929589 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-01 16:36:10 | INFO | fairseq_cli.preprocess | [None] Dictionary: 10008 types\n",
            "2023-04-01 16:36:11 | INFO | fairseq_cli.preprocess | [None] ptb_data/ptb.valid.txt: 3370 sents, 73760 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-01 16:36:11 | INFO | fairseq_cli.preprocess | [None] Dictionary: 10008 types\n",
            "2023-04-01 16:36:12 | INFO | fairseq_cli.preprocess | [None] ptb_data/ptb.test.txt: 3761 sents, 82430 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-01 16:36:12 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/ptb\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "TEXT=ptb_data\n",
        "fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --trainpref $TEXT/ptb.train.txt \\\n",
        "    --validpref $TEXT/ptb.valid.txt \\\n",
        "    --testpref $TEXT/ptb.test.txt \\\n",
        "    --destdir data-bin/ptb \\\n",
        "    --workers 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfnpNuG1e5h"
      },
      "source": [
        "One can add `--max-epoch 30` param to limit the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeifSDcC0TuJ",
        "outputId": "f502a5aa-dc25-4629-8cb1-0ac2eab18de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-01 17:51:00 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'logs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/ptb_transformer', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt', 'activation_fn': gelu, 'dropout': 0.3, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_attention_heads': 12, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ptb', 'sample_break_mode': none, 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-04-01 17:51:00 | INFO | fairseq.tasks.language_modeling | dictionary: 10008 types\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(10008, 768, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=768, out_features=10008, bias=False)\n",
            "  )\n",
            ")\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | num. shared model params: 57,901,056 (num. trained: 57,901,056)\n",
            "2023-04-01 17:51:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-04-01 17:51:01 | INFO | fairseq.data.data_utils | loaded 3,370 examples from: data-bin/ptb/valid\n",
            "2023-04-01 17:51:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-01 17:51:02 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-04-01 17:51:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-01 17:51:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-04-01 17:51:02 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-04-01 17:51:02 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/ptb_transformer/checkpoint_last.pt\n",
            "2023-04-01 17:51:03 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2023-04-01 17:51:03 | INFO | fairseq.trainer | Loaded checkpoint checkpoints/ptb_transformer/checkpoint_last.pt (epoch 19 @ 1026 updates)\n",
            "2023-04-01 17:51:03 | INFO | fairseq.trainer | loading train data for epoch 19\n",
            "2023-04-01 17:51:03 | INFO | fairseq.data.data_utils | loaded 42,068 examples from: data-bin/ptb/train\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 19\n",
            "2023-04-01 17:51:03 | INFO | fairseq_cli.train | begin dry-run validation on \"valid\" subset\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2023-04-01 17:51:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2023-04-01 17:51:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 17:51:03 | INFO | fairseq.trainer | begin training epoch 19\n",
            "2023-04-01 17:51:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2023-04-01 17:52:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 17:52:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:52:57.129596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-01 17:52:58.911379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-01 17:53:00 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-04-01 17:53:00 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.399 | nll_loss 7.52 | ppl 183.59 | wps 23265.6 | wpb 4040.9 | bsz 4 | num_updates 1083 | best_loss 8.399\n",
            "2023-04-01 17:53:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1083 updates\n",
            "2023-04-01 17:53:01 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:53:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 19 @ 1083 updates, score 8.399) (writing took 5.5725517150003725 seconds)\n",
            "2023-04-01 17:53:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2023-04-01 17:53:07 | INFO | train | epoch 019 | loss 8.075 | nll_loss 7.222 | ppl 149.26 | wps 7538 | ups 0.46 | wpb 16236.7 | bsz 15.9 | num_updates 1083 | lr 0.000135448 | gnorm 0.451 | train_wall 109 | gb_free 9.7 | wall 125\n",
            "2023-04-01 17:53:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:53:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 17:53:07 | INFO | fairseq.trainer | begin training epoch 20\n",
            "2023-04-01 17:53:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 17:53:40 | INFO | train_inner | epoch 020:     17 / 57 loss=8.058, nll_loss=7.201, ppl=147.18, wps=7703.4, ups=0.47, wpb=16270.6, bsz=15.9, num_updates=1100, lr=0.000137573, gnorm=0.45, train_wall=143, gb_free=9.7, wall=158\n",
            "2023-04-01 17:54:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 17:54:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:55:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.36 | nll_loss 7.47 | ppl 177.33 | wps 23203.9 | wpb 4040.9 | bsz 4 | num_updates 1140 | best_loss 8.36\n",
            "2023-04-01 17:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1140 updates\n",
            "2023-04-01 17:55:02 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 20 @ 1140 updates, score 8.36) (writing took 5.862494410000181 seconds)\n",
            "2023-04-01 17:55:07 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2023-04-01 17:55:07 | INFO | train | epoch 020 | loss 8.001 | nll_loss 7.135 | ppl 140.57 | wps 7678 | ups 0.47 | wpb 16236.7 | bsz 15.9 | num_updates 1140 | lr 0.000142572 | gnorm 0.446 | train_wall 111 | gb_free 9.7 | wall 245\n",
            "2023-04-01 17:55:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:55:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 17:55:07 | INFO | fairseq.trainer | begin training epoch 21\n",
            "2023-04-01 17:55:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 17:56:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 17:56:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:57:02 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.336 | nll_loss 7.442 | ppl 173.87 | wps 23317.1 | wpb 4040.9 | bsz 4 | num_updates 1197 | best_loss 8.336\n",
            "2023-04-01 17:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1197 updates\n",
            "2023-04-01 17:57:02 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:57:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 21 @ 1197 updates, score 8.336) (writing took 5.597079250000206 seconds)\n",
            "2023-04-01 17:57:08 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2023-04-01 17:57:08 | INFO | train | epoch 021 | loss 7.93 | nll_loss 7.051 | ppl 132.61 | wps 7688.7 | ups 0.47 | wpb 16236.7 | bsz 15.9 | num_updates 1197 | lr 0.000149695 | gnorm 0.443 | train_wall 111 | gb_free 9.7 | wall 365\n",
            "2023-04-01 17:57:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:57:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 17:57:08 | INFO | fairseq.trainer | begin training epoch 22\n",
            "2023-04-01 17:57:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 17:57:14 | INFO | train_inner | epoch 022:      3 / 57 loss=7.956, nll_loss=7.082, ppl=135.45, wps=7589.4, ups=0.47, wpb=16216.1, bsz=15.8, num_updates=1200, lr=0.00015007, gnorm=0.443, train_wall=195, gb_free=9.7, wall=372\n",
            "2023-04-01 17:59:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 17:59:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:59:03 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.326 | nll_loss 7.424 | ppl 171.7 | wps 23171.9 | wpb 4040.9 | bsz 4 | num_updates 1254 | best_loss 8.326\n",
            "2023-04-01 17:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1254 updates\n",
            "2023-04-01 17:59:03 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 17:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 22 @ 1254 updates, score 8.326) (writing took 5.755090927999845 seconds)\n",
            "2023-04-01 17:59:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2023-04-01 17:59:09 | INFO | train | epoch 022 | loss 7.857 | nll_loss 6.965 | ppl 124.95 | wps 7668 | ups 0.47 | wpb 16236.7 | bsz 15.9 | num_updates 1254 | lr 0.000156819 | gnorm 0.442 | train_wall 112 | gb_free 9.7 | wall 486\n",
            "2023-04-01 17:59:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 17:59:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 17:59:09 | INFO | fairseq.trainer | begin training epoch 23\n",
            "2023-04-01 17:59:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 18:00:40 | INFO | train_inner | epoch 023:     46 / 57 loss=7.818, nll_loss=6.92, ppl=121.08, wps=7926.7, ups=0.49, wpb=16298, bsz=15.9, num_updates=1300, lr=0.000162568, gnorm=0.442, train_wall=196, gb_free=9.7, wall=577\n",
            "2023-04-01 18:01:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 18:01:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 18:01:04 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.296 | nll_loss 7.39 | ppl 167.75 | wps 23242.1 | wpb 4040.9 | bsz 4 | num_updates 1311 | best_loss 8.296\n",
            "2023-04-01 18:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1311 updates\n",
            "2023-04-01 18:01:04 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 18:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 18:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 23 @ 1311 updates, score 8.296) (writing took 5.388658842999575 seconds)\n",
            "2023-04-01 18:01:09 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2023-04-01 18:01:09 | INFO | train | epoch 023 | loss 7.78 | nll_loss 6.875 | ppl 117.39 | wps 7705.8 | ups 0.47 | wpb 16236.7 | bsz 15.9 | num_updates 1311 | lr 0.000163942 | gnorm 0.442 | train_wall 111 | gb_free 9.7 | wall 607\n",
            "2023-04-01 18:01:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 18:01:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 18:01:09 | INFO | fairseq.trainer | begin training epoch 24\n",
            "2023-04-01 18:01:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 18:03:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-01 18:03:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 18:03:04 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.292 | nll_loss 7.369 | ppl 165.36 | wps 23230.6 | wpb 4040.9 | bsz 4 | num_updates 1368 | best_loss 8.292\n",
            "2023-04-01 18:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1368 updates\n",
            "2023-04-01 18:03:04 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 18:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "2023-04-01 18:03:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/ptb_transformer/checkpoint_best.pt (epoch 24 @ 1368 updates, score 8.292) (writing took 5.887432829999852 seconds)\n",
            "2023-04-01 18:03:10 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2023-04-01 18:03:10 | INFO | train | epoch 024 | loss 7.706 | nll_loss 6.788 | ppl 110.47 | wps 7670.3 | ups 0.47 | wpb 16236.7 | bsz 15.9 | num_updates 1368 | lr 0.000171066 | gnorm 0.445 | train_wall 111 | gb_free 9.7 | wall 727\n",
            "2023-04-01 18:03:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 18:03:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 57\n",
            "2023-04-01 18:03:10 | INFO | fairseq.trainer | begin training epoch 25\n",
            "2023-04-01 18:03:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-04-01 18:04:13 | INFO | train_inner | epoch 025:     32 / 57 loss=7.692, nll_loss=6.771, ppl=109.23, wps=7600.2, ups=0.47, wpb=16216.1, bsz=15.8, num_updates=1400, lr=0.000175065, gnorm=0.447, train_wall=195, gb_free=9.7, wall=791\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 205, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.9/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 331, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.9/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 843, in train_step\n",
            "    loss, sample_size_i, logging_output = self.task.train_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 536, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/content/fairseq/fairseq/optim/fairseq_optimizer.py\", line 96, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\", line 488, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "CPU times: user 4.15 s, sys: 507 ms, total: 4.66 s\n",
            "Wall time: 13min 25s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!fairseq-train \\\n",
        "    data-bin/ptb \\\n",
        "    --task language_modeling \\\n",
        "    --arch transformer_lm_gpt \\\n",
        "    --optimizer adam \\\n",
        "    --adam-betas '(0.9, 0.98)' \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-init-lr 1e-07 \\\n",
        "    --warmup-updates 4000 \\\n",
        "    --lr 0.0005 \\\n",
        "    --dropout 0.3 \\\n",
        "    --weight-decay 0.01 \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --update-freq 4 \\\n",
        "    --max-update 50000 \\\n",
        "    --save-dir checkpoints/ptb_transformer \\\n",
        "    --keep-last-epochs 5 \\\n",
        "    --tensorboard-logdir logs \\\n",
        "    --log-format simple \\\n",
        "    --log-interval 100 \\\n",
        "    --skip-invalid-size-inputs-valid-test \\\n",
        "    --save-interval-updates 1000 \\\n",
        "    --no-epoch-checkpoints \\\n",
        "    --patience 10 \\\n",
        "    --decoder-layers 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SdnMuph08kv",
        "outputId": "d4d1622c-ef1a-4be8-ad01-af2a683ee065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset...\n",
            "2023-04-01 19:34:19 | INFO | fairseq.tasks.language_modeling | dictionary: 10008 types\n",
            "Evaluating with bsz 10 tgt_len 64 ext_len 0 mem_len 640 clamp_len 400\n",
            "tensor(8.8265, device='cuda:0')\n",
            "tensor(8.6147, device='cuda:0')\n",
            "tensor(8.8769, device='cuda:0')\n",
            "tensor(8.7159, device='cuda:0')\n",
            "tensor(8.8462, device='cuda:0')\n",
            "tensor(8.5416, device='cuda:0')\n",
            "tensor(8.6901, device='cuda:0')\n",
            "tensor(8.4962, device='cuda:0')\n",
            "tensor(8.4816, device='cuda:0')\n",
            "tensor(8.4577, device='cuda:0')\n",
            "tensor(8.4627, device='cuda:0')\n",
            "tensor(8.2868, device='cuda:0')\n",
            "tensor(8.2996, device='cuda:0')\n",
            "tensor(8.6596, device='cuda:0')\n",
            "tensor(8.6688, device='cuda:0')\n",
            "tensor(8.7983, device='cuda:0')\n",
            "tensor(8.7969, device='cuda:0')\n",
            "tensor(8.6919, device='cuda:0')\n",
            "tensor(8.5465, device='cuda:0')\n",
            "tensor(8.6914, device='cuda:0')\n",
            "tensor(8.6630, device='cuda:0')\n",
            "tensor(8.7262, device='cuda:0')\n",
            "tensor(8.6886, device='cuda:0')\n",
            "tensor(8.5465, device='cuda:0')\n",
            "tensor(8.6244, device='cuda:0')\n",
            "tensor(8.5498, device='cuda:0')\n",
            "tensor(8.5896, device='cuda:0')\n",
            "tensor(8.5163, device='cuda:0')\n",
            "tensor(8.7584, device='cuda:0')\n",
            "tensor(8.5779, device='cuda:0')\n",
            "tensor(8.4927, device='cuda:0')\n",
            "tensor(8.5108, device='cuda:0')\n",
            "tensor(8.4750, device='cuda:0')\n",
            "tensor(8.5383, device='cuda:0')\n",
            "tensor(8.3532, device='cuda:0')\n",
            "tensor(8.7659, device='cuda:0')\n",
            "tensor(8.5645, device='cuda:0')\n",
            "tensor(8.6171, device='cuda:0')\n",
            "tensor(8.5044, device='cuda:0')\n",
            "tensor(8.7404, device='cuda:0')\n",
            "tensor(8.5456, device='cuda:0')\n",
            "tensor(8.4634, device='cuda:0')\n",
            "tensor(8.4667, device='cuda:0')\n",
            "tensor(8.5460, device='cuda:0')\n",
            "tensor(8.7012, device='cuda:0')\n",
            "tensor(8.7071, device='cuda:0')\n",
            "tensor(8.6240, device='cuda:0')\n",
            "tensor(8.3878, device='cuda:0')\n",
            "tensor(8.3950, device='cuda:0')\n",
            "tensor(8.2429, device='cuda:0')\n",
            "tensor(8.4886, device='cuda:0')\n",
            "tensor(8.6967, device='cuda:0')\n",
            "tensor(8.6785, device='cuda:0')\n",
            "tensor(8.9018, device='cuda:0')\n",
            "tensor(8.4988, device='cuda:0')\n",
            "tensor(8.5960, device='cuda:0')\n",
            "tensor(8.7767, device='cuda:0')\n",
            "tensor(8.6478, device='cuda:0')\n",
            "tensor(8.6134, device='cuda:0')\n",
            "tensor(8.5151, device='cuda:0')\n",
            "tensor(8.8364, device='cuda:0')\n",
            "tensor(8.6036, device='cuda:0')\n",
            "tensor(8.6040, device='cuda:0')\n",
            "tensor(8.2598, device='cuda:0')\n",
            "tensor(8.7052, device='cuda:0')\n",
            "tensor(8.6133, device='cuda:0')\n",
            "tensor(8.8063, device='cuda:0')\n",
            "tensor(8.5879, device='cuda:0')\n",
            "tensor(8.5525, device='cuda:0')\n",
            "tensor(8.5134, device='cuda:0')\n",
            "tensor(8.7878, device='cuda:0')\n",
            "tensor(8.6210, device='cuda:0')\n",
            "tensor(8.4175, device='cuda:0')\n",
            "tensor(8.7185, device='cuda:0')\n",
            "tensor(8.6875, device='cuda:0')\n",
            "tensor(8.6938, device='cuda:0')\n",
            "tensor(8.8890, device='cuda:0')\n",
            "tensor(8.8745, device='cuda:0')\n",
            "tensor(8.6141, device='cuda:0')\n",
            "tensor(8.4545, device='cuda:0')\n",
            "tensor(8.6734, device='cuda:0')\n",
            "tensor(8.8551, device='cuda:0')\n",
            "tensor(8.6073, device='cuda:0')\n",
            "tensor(8.5338, device='cuda:0')\n",
            "tensor(8.6647, device='cuda:0')\n",
            "tensor(8.4908, device='cuda:0')\n",
            "tensor(8.6393, device='cuda:0')\n",
            "tensor(8.4898, device='cuda:0')\n",
            "tensor(8.5728, device='cuda:0')\n",
            "tensor(8.8368, device='cuda:0')\n",
            "tensor(8.7152, device='cuda:0')\n",
            "tensor(8.8058, device='cuda:0')\n",
            "tensor(8.6068, device='cuda:0')\n",
            "tensor(8.6250, device='cuda:0')\n",
            "tensor(8.5490, device='cuda:0')\n",
            "tensor(8.6267, device='cuda:0')\n",
            "tensor(8.5919, device='cuda:0')\n",
            "tensor(8.4213, device='cuda:0')\n",
            "tensor(8.5952, device='cuda:0')\n",
            "tensor(8.6079, device='cuda:0')\n",
            "tensor(8.5118, device='cuda:0')\n",
            "tensor(8.6149, device='cuda:0')\n",
            "tensor(8.5316, device='cuda:0')\n",
            "tensor(8.4746, device='cuda:0')\n",
            "tensor(8.6434, device='cuda:0')\n",
            "tensor(8.5455, device='cuda:0')\n",
            "tensor(8.2981, device='cuda:0')\n",
            "tensor(8.4226, device='cuda:0')\n",
            "tensor(8.4142, device='cuda:0')\n",
            "tensor(8.3161, device='cuda:0')\n",
            "tensor(8.4784, device='cuda:0')\n",
            "tensor(8.6255, device='cuda:0')\n",
            "tensor(8.5445, device='cuda:0')\n",
            "tensor(8.2976, device='cuda:0')\n",
            "tensor(8.5400, device='cuda:0')\n",
            "tensor(8.4504, device='cuda:0')\n",
            "tensor(8.4556, device='cuda:0')\n",
            "tensor(8.5036, device='cuda:0')\n",
            "tensor(8.6716, device='cuda:0')\n",
            "tensor(8.4917, device='cuda:0')\n",
            "tensor(8.7741, device='cuda:0')\n",
            "tensor(8.7208, device='cuda:0')\n",
            "tensor(8.5994, device='cuda:0')\n",
            "tensor(8.6430, device='cuda:0')\n",
            "tensor(8.6325, device='cuda:0')\n",
            "tensor(8.6738, device='cuda:0')\n",
            "tensor(8.6803, device='cuda:0')\n",
            "tensor(8.6817, device='cuda:0')\n",
            "tensor(8.2765, device='cuda:0')\n",
            "Time : 3.15s, 24.44ms/segment\n",
            "====================================================================================================\n",
            "| test loss  8.59 | test ppl  5401.348 \n",
            "====================================================================================================\n",
            "CPU times: user 89.7 ms, sys: 15.3 ms, total: 105 ms\n",
            "Wall time: 8.77 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python eval.py \\\n",
        "        --cuda \\\n",
        "        --data penn \\\n",
        "        --dataset ptb \\\n",
        "        --tgt_len 64 \\\n",
        "        --mem_len 640 \\\n",
        "        --clamp_len 400 \\\n",
        "        --same_length \\\n",
        "        --split test \\\n",
        "        --work_dir checkpoints/ptb_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOmyr6k8TZA5",
        "outputId": "2bff5b6a-95ba-4c23-85ef-b511a7f4111b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-01 16:52:18 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 400, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ptb', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': 32, 'batch_size_valid': 32, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-04-01 16:52:18 | INFO | fairseq.tasks.language_modeling | dictionary: 10008 types\n",
            "2023-04-01 16:52:18 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "2023-04-01 16:52:19 | INFO | fairseq_cli.eval_lm | num. model params: 1,331,584\n",
            "2023-04-01 16:52:19 | INFO | fairseq.data.data_utils | loaded 3,761 examples from: data-bin/ptb/test\n",
            "2023-04-01 16:52:19 | INFO | fairseq_cli.eval_lm | data-bin/ptb test 736 examples\n",
            "2023-04-01 16:52:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-01 16:52:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2023-04-01 16:52:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2023-04-01 16:52:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2023-04-01 16:52:21 | INFO | fairseq_cli.eval_lm | Evaluated 82,430 tokens in 1.3s (61741.22 tokens/s)\n",
            "2023-04-01 16:52:21 | INFO | fairseq_cli.eval_lm | Loss (base 2): 7.3356, Perplexity: 161.53\n",
            "CPU times: user 84.7 ms, sys: 22.4 ms, total: 107 ms\n",
            "Wall time: 12.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!fairseq-eval-lm data-bin/ptb \\\n",
        "    --task language_modeling \\\n",
        "    --path checkpoints/ptb_transformer/checkpoint_best.pt \\\n",
        "    --gen-subset test \\\n",
        "    --batch-size 32 \\\n",
        "    --tokens-per-sample 512 \\\n",
        "    --context-window 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwEjoyHIWVIq",
        "outputId": "f6363f04-51b4-49bb-c0d9-52f702a106d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-01 16:51:58 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/ptb_transformer/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 400, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ptb', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': 32, 'batch_size_valid': 32, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-04-01 16:51:58 | INFO | fairseq.tasks.language_modeling | dictionary: 10008 types\n",
            "2023-04-01 16:51:58 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-eval-lm\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 343, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 253, in main\n",
            "    models, model_args, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/fairseq/fairseq/checkpoint_utils.py\", line 430, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: checkpoints/ptb_transformer/checkpoint_best.pt\n",
            "CPU times: user 32.9 ms, sys: 9.75 ms, total: 42.7 ms\n",
            "Wall time: 4.33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!fairseq-eval-lm data-bin/ptb \\\n",
        "    --task language_modeling \\\n",
        "    --path checkpoints/ptb_transformer/checkpoint_best.pt \\\n",
        "    --gen-subset valid \\\n",
        "    --batch-size 32 \\\n",
        "    --tokens-per-sample 512 \\\n",
        "    --context-window 400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QAdNIHqoJz"
      },
      "source": [
        "To save the state of your training and continue it on another machine, follow these steps:\n",
        "\n",
        "1. Make sure you've saved the checkpoints during training. By default, `fairseq-train` periodically saves checkpoints to the directory specified by the `--save-dir` option (in your case, `checkpoints/ptb_transformer`).\n",
        "\n",
        "2. If you want to stop the training and continue it later, you can either manually stop the training process or use the `--stop-time-hr` option to specify a maximum training time in hours.\n",
        "\n",
        "3. After stopping the training, compress the entire checkpoints directory:\n",
        "\n",
        "```bash\n",
        "tar -czvf ptb_transformer_checkpoints.tar.gz checkpoints/ptb_transformer\n",
        "```\n",
        "\n",
        "4. Transfer the compressed checkpoints file (`ptb_transformer_checkpoints.tar.gz`) to the new machine.\n",
        "\n",
        "5. On the new machine, decompress the checkpoints file:\n",
        "\n",
        "```bash\n",
        "tar -xzvf ptb_transformer_checkpoints.tar.gz\n",
        "```\n",
        "\n",
        "6. Ensure that you have the same environment (Python, fairseq, and other dependencies) on the new machine.\n",
        "\n",
        "7. Continue the training on the new machine using the `--restore-file` option to specify the latest checkpoint:\n",
        "\n",
        "```bash\n",
        "LAST_CHECKPOINT=checkpoints/ptb_transformer/checkpoint_last.pt\n",
        "\n",
        "fairseq-train data-bin/ptb \\\n",
        "    --task language_modeling \\\n",
        "    --arch transformer_lm \\\n",
        "    ... # other options\n",
        "    --restore-file $LAST_CHECKPOINT \\\n",
        "    --save-dir checkpoints/ptb_transformer \\\n",
        "    ... # other options\n",
        "```\n",
        "\n",
        "Replace `...` with the other options you used in your original `fairseq-train` command. This will continue the training from the last saved checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7AObZMyO57M"
      },
      "source": [
        "## WNT EN-DE 2016"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CKDZu8FTG-Q"
      },
      "source": [
        "### Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05rmKW59OBLq",
        "outputId": "55df0488-af29-4a78-e10a-3b5aa374f087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to wmt16ende. To change this, set the OUTPUT_DIR environment variable.\n",
            "Downloading Europarl v7. This may take a while...\n",
            "2023-04-06 16:38:41 URL:https://www.statmt.org/europarl/v7/de-en.tgz [197785698/197785698] -> \"wmt16ende/data/europarl-v7-de-en.tgz\" [1]\n",
            "Downloading Common Crawl corpus. This may take a while...\n",
            "2023-04-06 16:45:19 URL:https://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz [918311367/918311367] -> \"wmt16ende/data/common-crawl.tgz\" [1]\n",
            "Downloading News Commentary v11. This may take a while...\n",
            "2023-04-06 16:45:23 URL:https://data.statmt.org/wmt16/translation-task/training-parallel-nc-v11.tgz [75178032/75178032] -> \"wmt16ende/data/nc-v11.tgz\" [1]\n",
            "Downloading dev/test sets\n",
            "2023-04-06 16:45:25 URL:https://data.statmt.org/wmt16/translation-task/dev.tgz [22836484/22836484] -> \"wmt16ende/data/dev.tgz\" [1]\n",
            "2023-04-06 16:45:27 URL:https://data.statmt.org/wmt16/translation-task/test.tgz [3785707/3785707] -> \"wmt16ende/data/test.tgz\" [1]\n",
            "Extracting all files...\n",
            "europarl-v7.de-en.de\n",
            "europarl-v7.de-en.en\n",
            "commoncrawl.cs-en.annotation\n",
            "commoncrawl.cs-en.cs\n",
            "commoncrawl.cs-en.en\n",
            "commoncrawl.de-en.annotation\n",
            "commoncrawl.de-en.de\n",
            "commoncrawl.de-en.en\n",
            "commoncrawl.es-en.annotation\n",
            "commoncrawl.es-en.en\n",
            "commoncrawl.es-en.es\n",
            "commoncrawl.fr-en.annotation\n",
            "commoncrawl.fr-en.en\n",
            "commoncrawl.fr-en.fr\n",
            "commoncrawl.ru-en.annotation\n",
            "commoncrawl.ru-en.en\n",
            "commoncrawl.ru-en.ru\n",
            "training-parallel-nc-v11/\n",
            "training-parallel-nc-v11/news-commentary-v11.ru-en.ru\n",
            "training-parallel-nc-v11/news-commentary-v11.cs-en.en\n",
            "training-parallel-nc-v11/news-commentary-v11.de-en.de\n",
            "training-parallel-nc-v11/news-commentary-v11.ru-en.en\n",
            "training-parallel-nc-v11/news-commentary-v11.cs-en.cs\n",
            "training-parallel-nc-v11/news-commentary-v11.de-en.en\n",
            "dev/\n",
            "dev/newstest2009-ref.fr.sgm\n",
            "dev/newstest2013.es\n",
            "dev/newstest2014-deen-src.de.sgm\n",
            "dev/newstest2015-ruen-src.ru.sgm\n",
            "dev/newstest2010-ref.de.sgm\n",
            "dev/newstest2012-src.fr.sgm\n",
            "dev/newstest2014-ruen-ref.ru.sgm\n",
            "dev/news-test2008.en\n",
            "dev/news-test2008.es\n",
            "dev/newstest2009-ref.hu.sgm\n",
            "dev/newstest2014-csen-ref.en.sgm\n",
            "dev/newsdiscussdev2015-enfr-src.en.sgm\n",
            "dev/newstest2010.cs\n",
            "dev/news-test2008-src.hu.sgm\n",
            "dev/.newsdev2014-ref.en.sgm.swp\n",
            "dev/newstest2011-ref.cs.sgm\n",
            "dev/newstest2011-ref.fr.sgm\n",
            "dev/newsdev2016-enro-ref.ro.sgm\n",
            "dev/newstest2011.cs\n",
            "dev/newstest2009.es\n",
            "dev/newstest2011.en\n",
            "dev/newsdev2015-enfi-src.en.sgm\n",
            "dev/newstest2013.cs\n",
            "dev/newstest2012-ref.es.sgm\n",
            "dev/newstest2014-csen-ref.cs.sgm\n",
            "dev/newsdev2014-src.hi.sgm\n",
            "dev/newstest2015-encs-src.en.sgm\n",
            "dev/newsdev2014-src.en.sgm\n",
            "dev/newsdev2015-enfi-ref.fi.sgm\n",
            "dev/newstest2011-ref.es.sgm\n",
            "dev/newstest2013-src.ru.sgm\n",
            "dev/newstest2012-src.de.sgm\n",
            "dev/newsdev2016-tren-ref.en.sgm\n",
            "dev/newstest2011-src.fr.sgm\n",
            "dev/newssyscomb2009-src.de.sgm\n",
            "dev/newstest2012-src.es.sgm\n",
            "dev/newstest2010-ref.cs.sgm\n",
            "dev/newstest2014-hien-ref.hi.sgm\n",
            "dev/newssyscomb2009.de\n",
            "dev/newstest2011-ref.en.sgm\n",
            "dev/news-test2008.cs\n",
            "dev/newstest2010.en\n",
            "dev/newssyscomb2009.fr\n",
            "dev/newstest2012-ref.en.sgm\n",
            "dev/news-test2008.de\n",
            "dev/newstest2011.de\n",
            "dev/newstest2012.es\n",
            "dev/newsdev2016-entr-ref.tr.sgm\n",
            "dev/newstest2011-ref.de.sgm\n",
            "dev/newsdev2014-ref.hi.sgm\n",
            "dev/newstest2013-src.de.sgm\n",
            "dev/newstest2012-ref.fr.sgm\n",
            "dev/newstest2009.de\n",
            "dev/newstest2012.en\n",
            "dev/news-test2008-ref.cs.sgm\n",
            "dev/newstest2013-ref.fr.sgm\n",
            "dev/newsdev2014.hi\n",
            "dev/newstest2011-src.cs.sgm\n",
            "dev/newssyscomb2009-src.fr.sgm\n",
            "dev/newstest2012.ru\n",
            "dev/newstest2010-ref.es.sgm\n",
            "dev/newstest2010-src.es.sgm\n",
            "dev/news-test2008.fr\n",
            "dev/newstest2009.en\n",
            "dev/newstest2014-ruen-src.ru.sgm\n",
            "dev/newssyscomb2009-ref.cs.sgm\n",
            "dev/newstest2010-src.fr.sgm\n",
            "dev/newssyscomb2009-src.en.sgm\n",
            "dev/newstest2015-enru-ref.ru.sgm\n",
            "dev/newstest2015-ende-ref.de.sgm\n",
            "dev/newstest2013-ref.ru.sgm\n",
            "dev/newssyscomb2009-src.it.sgm\n",
            "dev/newsdiscusstest2015-enfr-src.en.sgm\n",
            "dev/newstest2015-fien-ref.en.sgm\n",
            "dev/newstest2010-src.en.sgm\n",
            "dev/newstest2009.fr\n",
            "dev/newstest2015-ruen-ref.en.sgm\n",
            "dev/newstest2013-src.es.sgm\n",
            "dev/newstest2014-hien-ref.en.sgm\n",
            "dev/news-test2008-src.en.sgm\n",
            "dev/newstest2012-ref.cs.sgm\n",
            "dev/news-test2008-ref.es.sgm\n",
            "dev/news-test2008-ref.fr.sgm\n",
            "dev/newstest2014-ruen-ref.en.sgm\n",
            "dev/news-test2008-src.es.sgm\n",
            "dev/newstest2014-fren-src.en.sgm\n",
            "dev/newstest2012-ref.de.sgm\n",
            "dev/newstest2014-csen-src.cs.sgm\n",
            "dev/newstest2014-csen-src.en.sgm\n",
            "dev/newstest2011-src.de.sgm\n",
            "dev/newssyscomb2009-src.cs.sgm\n",
            "dev/newstest2015-enfi-ref.fi.sgm\n",
            "dev/newstest2009-src.it.sgm\n",
            "dev/newstest2010-src.de.sgm\n",
            "dev/newstest2009-ref.cs.sgm\n",
            "dev/newssyscomb2009-ref.es.sgm\n",
            "dev/newstest2014-deen-src.en.sgm\n",
            "dev/newsdiscusstest2015-fren-ref.en.sgm\n",
            "dev/newstest2012.fr\n",
            "dev/newsdiscusstest2015-enfr-ref.fr.sgm\n",
            "dev/newsdev2016-enro-src.en.sgm\n",
            "dev/newstest2009-src.es.sgm\n",
            "dev/newstest2013-src.fr.sgm\n",
            "dev/newstest2015-deen-src.de.sgm\n",
            "dev/newsdev2015-fien-src.fi.sgm\n",
            "dev/newsdiscusstest2015-fren-src.fr.sgm\n",
            "dev/newstest2014-ruen-src.en.sgm\n",
            "dev/newstest2012-src.en.sgm\n",
            "dev/newstest2013.fr\n",
            "dev/newstest2015-enru-src.en.sgm\n",
            "dev/newstest2009-ref.es.sgm\n",
            "dev/newstest2011.fr\n",
            "dev/newstest2009-ref.en.sgm\n",
            "dev/newstest2015-enfi-src.en.sgm\n",
            "dev/newstest2009-src.xx.sgm\n",
            "dev/newstest2015-encs-ref.cs.sgm\n",
            "dev/newstest2013.ru\n",
            "dev/newstest2009.cs\n",
            "dev/newsdev2014.en\n",
            "dev/newstest2014-fren-ref.fr.sgm\n",
            "dev/news-test2008-ref.en.sgm\n",
            "dev/newssyscomb2009.es\n",
            "dev/news-test2008-src.cs.sgm\n",
            "dev/newsdev2016-roen-src.ro.sgm\n",
            "dev/.newstest2013-ref.en.sgm.swp\n",
            "dev/newssyscomb2009-ref.hu.sgm\n",
            "dev/newstest2010.de\n",
            "dev/newstest2013-ref.cs.sgm\n",
            "dev/newstest2013-ref.de.sgm\n",
            "dev/newstest2009-src.cs.sgm\n",
            "dev/newssyscomb2009.en\n",
            "dev/newssyscomb2009-ref.it.sgm\n",
            "dev/newstest2009-ref.it.sgm\n",
            "dev/newstest2010-ref.fr.sgm\n",
            "dev/newstest2015-csen-src.cs.sgm\n",
            "dev/newsdev2016-entr-src.en.sgm\n",
            "dev/newstest2010.es\n",
            "dev/news-test2008-src.de.sgm\n",
            "dev/newstest2013.en\n",
            "dev/newsdev2016-roen-ref.en.sgm\n",
            "dev/newstest2009-src.de.sgm\n",
            "dev/newstest2010-ref.en.sgm\n",
            "dev/newstest2011-src.es.sgm\n",
            "dev/newssyscomb2009-ref.en.sgm\n",
            "dev/newstest2014-fren-ref.en.sgm\n",
            "dev/newstest2012.cs\n",
            "dev/newstest2009-src.hu.sgm\n",
            "dev/newstest2009-src.fr.sgm\n",
            "dev/newstest2015-ende-src.en.sgm\n",
            "dev/newstest2013-src.cs.sgm\n",
            "dev/newstest2014-hien-src.hi.sgm\n",
            "dev/news-test2008-ref.hu.sgm\n",
            "dev/newstest2015-csen-ref.en.sgm\n",
            "dev/newstest2013-ref.es.sgm\n",
            "dev/newstest2013-ref.en.sgm\n",
            "dev/newstest2010-src.cs.sgm\n",
            "dev/newstest2010.fr\n",
            "dev/newstest2015-deen-ref.en.sgm\n",
            "dev/newstest2011.es\n",
            "dev/newsdev2016-tren-src.tr.sgm\n",
            "dev/newstest2013.de\n",
            "dev/newstest2014-fren-src.fr.sgm\n",
            "dev/newsdiscussdev2015-fren-ref.en.sgm\n",
            "dev/newsdiscussdev2015-fren-src.fr.sgm\n",
            "dev/newstest2014-deen-ref.de.sgm\n",
            "dev/newstest2013-src.en.sgm\n",
            "dev/newssyscomb2009-ref.fr.sgm\n",
            "dev/newssyscomb2009-ref.de.sgm\n",
            "dev/newstest2009-src.en.sgm\n",
            "dev/newstest2009-ref.de.sgm\n",
            "dev/newsdiscussdev2015-enfr-ref.fr.sgm\n",
            "dev/newssyscomb2009.cs\n",
            "dev/newstest2012-ref.ru.sgm\n",
            "dev/newstest2014-hien-src.en.sgm\n",
            "dev/news-test2008-src.fr.sgm\n",
            "dev/newsdev2015-fien-ref.en.sgm\n",
            "dev/newsdev2014-ref.en.sgm\n",
            "dev/newstest2015-fien-src.fi.sgm\n",
            "dev/news-test2008-ref.de.sgm\n",
            "dev/newstest2012-src.ru.sgm\n",
            "dev/newssyscomb2009-src.es.sgm\n",
            "dev/newssyscomb2009-src.hu.sgm\n",
            "dev/newstest2014-deen-ref.en.sgm\n",
            "dev/newstest2012.de\n",
            "dev/newstest2011-src.en.sgm\n",
            "dev/newstest2012-src.cs.sgm\n",
            "test/newstest2016-csen-ref.en.sgm\n",
            "test/newstest2016-csen-src.cs.sgm\n",
            "test/newstest2016-deen-ref.en.sgm\n",
            "test/newstest2016-deen-src.de.sgm\n",
            "test/newstest2016-encs-ref.cs.sgm\n",
            "test/newstest2016-encs-src.en.sgm\n",
            "test/newstest2016-ende-ref.de.sgm\n",
            "test/newstest2016-ende-src.en.sgm\n",
            "test/newstest2016-enfi-ref.fi.sgm\n",
            "test/newstest2016-enfi-src.en.sgm\n",
            "test/newstest2016-enro-ref.ro.sgm\n",
            "test/newstest2016-enro-src.en.sgm\n",
            "test/newstest2016-enru-ref.ru.sgm\n",
            "test/newstest2016-enru-src.en.sgm\n",
            "test/newstest2016-entr-ref.tr.sgm\n",
            "test/newstest2016-entr-src.en.sgm\n",
            "test/newstest2016-fien-ref.en.sgm\n",
            "test/newstest2016-fien-src.fi.sgm\n",
            "test/newstest2016-roen-ref.en.sgm\n",
            "test/newstest2016-roen-src.ro.sgm\n",
            "test/newstest2016-ruen-ref.en.sgm\n",
            "test/newstest2016-ruen-src.ru.sgm\n",
            "test/newstest2016-tren-ref.en.sgm\n",
            "test/newstest2016-tren-src.tr.sgm\n",
            "test/newstestB2016-enfi-ref.fi.sgm\n",
            "test/newstestB2016-enfi-src.en.sgm\n",
            "Cloning moses for data processing\n",
            "Cloning into './mosesdecoder'...\n",
            "remote: Enumerating objects: 148097, done.\u001b[K\n",
            "remote: Counting objects: 100% (525/525), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 148097 (delta 323), reused 441 (delta 292), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148097/148097), 129.88 MiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (114349/114349), done.\n",
            "4562102 wmt16ende/train.en\n",
            "4562102 wmt16ende/train.de\n",
            "Tokenizing wmt16ende/newstest2009.de...\n",
            "Tokenizing wmt16ende/newstest2010.de...\n",
            "Tokenizing wmt16ende/newstest2011.de...\n",
            "Tokenizing wmt16ende/newstest2012.de...\n",
            "Tokenizing wmt16ende/newstest2013.de...\n",
            "Tokenizing wmt16ende/newstest2014.de...\n",
            "Tokenizing wmt16ende/newstest2015.de...\n",
            "Tokenizing wmt16ende/newstest2016.de...\n",
            "Tokenizing wmt16ende/train.de...\n",
            "Tokenizing wmt16ende/newstest2009.en...\n",
            "Tokenizing wmt16ende/newstest2010.en...\n",
            "Tokenizing wmt16ende/newstest2011.en...\n",
            "Tokenizing wmt16ende/newstest2012.en...\n",
            "Tokenizing wmt16ende/newstest2013.en...\n",
            "Tokenizing wmt16ende/newstest2014.en...\n",
            "Tokenizing wmt16ende/newstest2015.en...\n",
            "Tokenizing wmt16ende/newstest2016.en...\n",
            "Tokenizing wmt16ende/train.en...\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 597 (delta 8), reused 12 (delta 4), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (597/597), 252.23 KiB | 3.19 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n",
            "Learning BPE with merge_ops=32000. This may take a while...\n",
            "/content/subword-nmt/learn_bpe.py:335: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "100% 32000/32000 [19:30<00:00, 27.33it/s]\n",
            "Apply BPE with merge_ops=32000 to tokenized files...\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2009.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2010.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2011.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2012.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2013.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2014.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2015.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2016.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/train.tok.bpe.32000.en\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2009.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2010.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2011.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2012.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2013.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2014.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2015.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/newstest2016.tok.bpe.32000.de\n",
            "/content/subword-nmt/apply_bpe.py:393: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "wmt16ende/train.tok.bpe.32000.de\n",
            "Cleaning ...\n",
            "clean-corpus.perl: processing wmt16ende/train.tok.bpe.32000.en & .de to wmt16ende/train.tok.clean.bpe.32000, cutoff 3-150, ratio 1.5\n",
            "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000)..........(3400000)..........(3500000)..........(3600000)..........(3700000)..........(3800000)..........(3900000)..........(4000000)..........(4100000)..........(4200000)..........(4300000)..........(4400000)..........(4500000)......\n",
            "Input sentences: 4562102  Output sentences:  3963848\n",
            "/content/subword-nmt/get_vocab.py:57: DeprecationWarning: this script's location has moved to /content/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  warnings.warn(\n",
            "All done.\n"
          ]
        }
      ],
      "source": [
        "!sh prepare-wmt16en2de.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jugMQpIdnLsW",
        "outputId": "222e5673-9a50-4712-ffb2-12018f33340a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bpe.32000\t\t       newstest2013.tok.de\n",
            "data\t\t\t       newstest2013.tok.en\n",
            "newstest2009.de\t\t       newstest2014.de\n",
            "newstest2009.en\t\t       newstest2014.en\n",
            "newstest2009.tok.bpe.32000.de  newstest2014.tok.bpe.32000.de\n",
            "newstest2009.tok.bpe.32000.en  newstest2014.tok.bpe.32000.en\n",
            "newstest2009.tok.de\t       newstest2014.tok.de\n",
            "newstest2009.tok.en\t       newstest2014.tok.en\n",
            "newstest2010.de\t\t       newstest2015.de\n",
            "newstest2010.en\t\t       newstest2015.en\n",
            "newstest2010.tok.bpe.32000.de  newstest2015.tok.bpe.32000.de\n",
            "newstest2010.tok.bpe.32000.en  newstest2015.tok.bpe.32000.en\n",
            "newstest2010.tok.de\t       newstest2015.tok.de\n",
            "newstest2010.tok.en\t       newstest2015.tok.en\n",
            "newstest2011.de\t\t       newstest2016.de\n",
            "newstest2011.en\t\t       newstest2016.en\n",
            "newstest2011.tok.bpe.32000.de  newstest2016.tok.bpe.32000.de\n",
            "newstest2011.tok.bpe.32000.en  newstest2016.tok.bpe.32000.en\n",
            "newstest2011.tok.de\t       newstest2016.tok.de\n",
            "newstest2011.tok.en\t       newstest2016.tok.en\n",
            "newstest2012.de\t\t       train.de\n",
            "newstest2012.en\t\t       train.en\n",
            "newstest2012.tok.bpe.32000.de  train.tok.bpe.32000.de\n",
            "newstest2012.tok.bpe.32000.en  train.tok.bpe.32000.en\n",
            "newstest2012.tok.de\t       train.tok.clean.bpe.32000.de\n",
            "newstest2012.tok.en\t       train.tok.clean.bpe.32000.en\n",
            "newstest2013.de\t\t       train.tok.de\n",
            "newstest2013.en\t\t       train.tok.en\n",
            "newstest2013.tok.bpe.32000.de  vocab.bpe.32000\n",
            "newstest2013.tok.bpe.32000.en\n"
          ]
        }
      ],
      "source": [
        "!ls wmt16ende"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc4RffIpojGr",
        "outputId": "ab8d0cd0-12b5-4cd3-e2fd-5e85bbc82803"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-06 17:46:23.967423: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-06 17:46:26.623178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-06 17:46:34 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='de', trainpref='wmt16ende/train.tok.clean.bpe.32000', validpref='wmt16ende/newstest2013.tok.bpe.32000', testpref='wmt16ende/newstest2014.tok.bpe.32000', align_suffix=None, destdir='data-bin/wmt16ende', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=33000, nwordssrc=33000, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=32, dict_only=False)\n",
            "2023-04-06 17:54:32 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33000 types\n",
            "2023-04-06 18:11:39 | INFO | fairseq_cli.preprocess | [en] wmt16ende/train.tok.clean.bpe.32000.en: 3963848 sents, 118076098 tokens, 0.00261% replaced (by <unk>)\n",
            "2023-04-06 18:11:39 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33000 types\n",
            "2023-04-06 18:11:42 | INFO | fairseq_cli.preprocess | [en] wmt16ende/newstest2013.tok.bpe.32000.en: 3000 sents, 78094 tokens, 0.00128% replaced (by <unk>)\n",
            "2023-04-06 18:11:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33000 types\n",
            "2023-04-06 18:11:44 | INFO | fairseq_cli.preprocess | [en] wmt16ende/newstest2014.tok.bpe.32000.en: 3003 sents, 82611 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-06 18:11:44 | INFO | fairseq_cli.preprocess | [de] Dictionary: 33000 types\n",
            "2023-04-06 18:30:12 | INFO | fairseq_cli.preprocess | [de] wmt16ende/train.tok.clean.bpe.32000.de: 3963848 sents, 122028489 tokens, 0.00245% replaced (by <unk>)\n",
            "2023-04-06 18:30:12 | INFO | fairseq_cli.preprocess | [de] Dictionary: 33000 types\n",
            "2023-04-06 18:30:16 | INFO | fairseq_cli.preprocess | [de] wmt16ende/newstest2013.tok.bpe.32000.de: 3000 sents, 83695 tokens, 0.00119% replaced (by <unk>)\n",
            "2023-04-06 18:30:16 | INFO | fairseq_cli.preprocess | [de] Dictionary: 33000 types\n",
            "2023-04-06 18:30:18 | INFO | fairseq_cli.preprocess | [de] wmt16ende/newstest2014.tok.bpe.32000.de: 3003 sents, 87068 tokens, 0.882% replaced (by <unk>)\n",
            "2023-04-06 18:30:18 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wmt16ende\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 13.2 s, sys: 1.61 s, total: 14.8 s\n",
            "Wall time: 44min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%bash\n",
        "TEXT=wmt16ende\n",
        "fairseq-preprocess \\\n",
        "    --source-lang en --target-lang de \\\n",
        "    --trainpref $TEXT/train.tok.clean.bpe.32000 \\\n",
        "    --validpref $TEXT/newstest2013.tok.bpe.32000 \\\n",
        "    --testpref $TEXT/newstest2014.tok.bpe.32000 \\\n",
        "    --destdir data-bin/wmt16ende \\\n",
        "    --nwordssrc 33000 --nwordstgt 33000 \\\n",
        "    --joined-dictionary \\\n",
        "    --workers 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xzXpOpiTO49"
      },
      "source": [
        "### Load from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCB5fHvm97-n",
        "outputId": "f62e81dd-8ef6-4f9b-9c22-bc66f68554d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bFTCcoD9_ov",
        "outputId": "af5d79c8-a7a6-46be-c20b-36ceb7e38621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  fairseq\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2oCauhbRpiJ",
        "outputId": "de9f2260-4607-478e-b7e2-d451d73ff05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict.de.txt\t   test.en-de.de.idx   train.en-de.de.idx  valid.en-de.de.idx\n",
            "dict.en.txt\t   test.en-de.en.bin   train.en-de.en.bin  valid.en-de.en.bin\n",
            "preprocess.log\t   test.en-de.en.idx   train.en-de.en.idx  valid.en-de.en.idx\n",
            "test.en-de.de.bin  train.en-de.de.bin  valid.en-de.de.bin  wmt16ende\n"
          ]
        }
      ],
      "source": [
        "!mkdir data-bin\n",
        "!cp -R drive/MyDrive/content/wmt16ende data-bin/wmt16ende\n",
        "!ls data-bin/wmt16ende"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvlL6faTNTS"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CtD7-dRQpgf",
        "outputId": "cf3e3c52-5250-4b7d-c142-a67f734dcb20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-07 10:49:00.771586: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-07 10:49:02.040062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 10:49:04 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-04-07 10:49:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de', max_epoch=30, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin/wmt16ende', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_path=None, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16ende', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-04-07 10:49:08 | INFO | fairseq.tasks.translation | [en] dictionary: 33000 types\n",
            "2023-04-07 10:49:08 | INFO | fairseq.tasks.translation | [de] dictionary: 33000 types\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33000, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33000, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=33000, bias=False)\n",
            "  )\n",
            ")\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | num. shared model params: 77,930,496 (num. trained: 77,930,496)\n",
            "2023-04-07 10:49:09 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-04-07 10:49:09 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16ende/valid.en-de.en\n",
            "2023-04-07 10:49:09 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16ende/valid.en-de.de\n",
            "2023-04-07 10:49:09 | INFO | fairseq.tasks.translation | data-bin/wmt16ende valid en-de 3000 examples\n",
            "2023-04-07 10:49:13 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2023-04-07 10:49:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-07 10:49:13 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-04-07 10:49:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-07 10:49:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-04-07 10:49:13 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-04-07 10:49:13 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2023-04-07 10:49:13 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2023-04-07 10:49:14 | INFO | fairseq.trainer | Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)\n",
            "2023-04-07 10:49:14 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-04-07 10:49:14 | INFO | fairseq.data.data_utils | loaded 3,963,848 examples from: data-bin/wmt16ende/train.en-de.en\n",
            "2023-04-07 10:49:14 | INFO | fairseq.data.data_utils | loaded 3,963,848 examples from: data-bin/wmt16ende/train.en-de.de\n",
            "2023-04-07 10:49:14 | INFO | fairseq.tasks.translation | data-bin/wmt16ende train en-de 3963848 examples\n",
            "2023-04-07 10:49:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-07 10:49:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2023-04-07 10:49:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2023-04-07 10:49:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2023-04-07 10:49:15 | INFO | fairseq_cli.train | begin dry-run validation on \"valid\" subset\n",
            "2023-04-07 10:49:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2023-04-07 10:49:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2023-04-07 10:49:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2023-04-07 10:49:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2023-04-07 10:49:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32474\n",
            "epoch 001:   0% 0/32474 [00:00<?, ?it/s]2023-04-07 10:49:16 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-04-07 10:49:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "epoch 001:   0% 37/32474 [00:19<4:30:32,  2.00it/s]/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "epoch 001:   3% 999/32474 [08:03<4:11:13,  2.09it/s, loss=9.763, nll_loss=8.912, ppl=481.65, wps=7714.7, ups=2.06, wpb=3743.6, bsz=117.3, num_updates=1900, lr=0.0002375, gnorm=1.112, train_wall=48, gb_free=11.3, wall=0]2023-04-07 10:57:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-07 10:57:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/31 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 1/31 [00:01<00:33,  1.12s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 2/31 [00:02<00:31,  1.09s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 3/31 [00:03<00:34,  1.23s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 4/31 [00:05<00:35,  1.30s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 5/31 [00:06<00:35,  1.37s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 6/31 [00:07<00:34,  1.37s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 7/31 [00:09<00:31,  1.30s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 8/31 [00:10<00:30,  1.34s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 9/31 [00:11<00:29,  1.36s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 10/31 [00:13<00:29,  1.38s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 11/31 [00:14<00:27,  1.35s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 12/31 [00:15<00:25,  1.32s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 13/31 [00:17<00:23,  1.31s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 14/31 [00:18<00:23,  1.37s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 15/31 [00:20<00:23,  1.46s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 16/31 [00:21<00:22,  1.51s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 17/31 [00:23<00:21,  1.56s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 18/31 [00:24<00:19,  1.47s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 19/31 [00:26<00:17,  1.46s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 20/31 [00:27<00:15,  1.40s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 21/31 [00:28<00:13,  1.40s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 22/31 [00:30<00:12,  1.37s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 23/31 [00:31<00:11,  1.38s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 24/31 [00:33<00:09,  1.40s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 25/31 [00:34<00:09,  1.53s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 26/31 [00:36<00:08,  1.65s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 27/31 [00:38<00:06,  1.73s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 28/31 [00:40<00:05,  1.69s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 29/31 [00:41<00:03,  1.66s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 30/31 [00:43<00:01,  1.71s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 31/31 [00:45<00:00,  1.75s/it]\u001b[A\n",
            "                                                                        \u001b[A2023-04-07 10:58:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.794 | nll_loss 8.912 | ppl 481.68 | bleu 0.77 | wps 1837.8 | wpb 2699.8 | bsz 96.8 | num_updates 2000 | best_bleu 0.77\n",
            "2023-04-07 10:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 2000 updates\n",
            "2023-04-07 10:58:05 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint_1_2000.pt\n",
            "2023-04-07 10:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint_1_2000.pt\n",
            "2023-04-07 10:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.77) (writing took 12.392107807999992 seconds)\n",
            "epoch 001:   6% 1999/32474 [17:04<4:01:23,  2.10it/s, loss=9.046, nll_loss=8.085, ppl=271.5, wps=7787.9, ups=2.08, wpb=3752.2, bsz=131.7, num_updates=2900, lr=0.0003625, gnorm=1.092, train_wall=48, gb_free=11.1, wall=0]2023-04-07 11:06:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-07 11:06:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/31 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 1/31 [00:01<00:31,  1.05s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 2/31 [00:01<00:27,  1.05it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 3/31 [00:03<00:28,  1.01s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 4/31 [00:04<00:27,  1.03s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 5/31 [00:05<00:27,  1.05s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 6/31 [00:06<00:25,  1.02s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 7/31 [00:07<00:24,  1.01s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 8/31 [00:08<00:24,  1.07s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 9/31 [00:09<00:24,  1.10s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 10/31 [00:10<00:25,  1.22s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 11/31 [00:12<00:25,  1.28s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 12/31 [00:13<00:24,  1.30s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 13/31 [00:15<00:24,  1.35s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 14/31 [00:16<00:22,  1.33s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 15/31 [00:17<00:21,  1.33s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 16/31 [00:19<00:20,  1.34s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 17/31 [00:20<00:19,  1.36s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 18/31 [00:21<00:17,  1.36s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 19/31 [00:23<00:16,  1.41s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 20/31 [00:24<00:15,  1.39s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 21/31 [00:26<00:15,  1.52s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 22/31 [00:28<00:14,  1.61s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 23/31 [00:30<00:13,  1.70s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 24/31 [00:32<00:11,  1.71s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 25/31 [00:33<00:10,  1.74s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 26/31 [00:35<00:08,  1.80s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 27/31 [00:37<00:07,  1.82s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 28/31 [00:39<00:05,  1.89s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 29/31 [00:41<00:03,  1.99s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 30/31 [00:44<00:02,  2.18s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 31/31 [00:46<00:00,  2.20s/it]\u001b[A\n",
            "                                                                        \u001b[A2023-04-07 11:07:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.245 | nll_loss 8.273 | ppl 309.41 | bleu 1.03 | wps 1787 | wpb 2699.8 | bsz 96.8 | num_updates 3000 | best_bleu 1.03\n",
            "2023-04-07 11:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3000 updates\n",
            "2023-04-07 11:07:08 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint_1_3000.pt\n",
            "2023-04-07 11:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint_1_3000.pt\n",
            "2023-04-07 11:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 1.03) (writing took 12.379485926999678 seconds)\n",
            "epoch 001:   9% 2999/32474 [26:05<3:59:22,  2.05it/s, loss=8.61, nll_loss=7.584, ppl=191.87, wps=7816.5, ups=2.06, wpb=3792.2, bsz=137.9, num_updates=3900, lr=0.0004875, gnorm=1.016, train_wall=48, gb_free=10.9, wall=0]2023-04-07 11:15:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2023-04-07 11:15:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/31 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 1/31 [00:01<00:37,  1.24s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 2/31 [00:02<00:35,  1.21s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 3/31 [00:03<00:37,  1.34s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 4/31 [00:05<00:37,  1.40s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 5/31 [00:07<00:38,  1.49s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  19% 6/31 [00:08<00:34,  1.38s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 7/31 [00:09<00:31,  1.33s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  26% 8/31 [00:10<00:31,  1.39s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  29% 9/31 [00:12<00:30,  1.41s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 10/31 [00:13<00:30,  1.46s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 11/31 [00:15<00:28,  1.44s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 12/31 [00:16<00:26,  1.41s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 13/31 [00:18<00:26,  1.46s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 14/31 [00:19<00:25,  1.52s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 15/31 [00:21<00:25,  1.61s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 16/31 [00:23<00:23,  1.59s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 17/31 [00:24<00:22,  1.57s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 18/31 [00:26<00:19,  1.53s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 19/31 [00:27<00:18,  1.54s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 20/31 [00:29<00:16,  1.49s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 21/31 [00:30<00:14,  1.50s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  71% 22/31 [00:32<00:13,  1.50s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  74% 23/31 [00:34<00:12,  1.60s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 24/31 [00:36<00:11,  1.70s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 25/31 [00:37<00:10,  1.77s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  84% 26/31 [00:39<00:08,  1.77s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 27/31 [00:41<00:06,  1.74s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 28/31 [00:43<00:05,  1.78s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 29/31 [00:44<00:03,  1.77s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 30/31 [00:46<00:01,  1.81s/it]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 31/31 [00:49<00:00,  2.03s/it]\u001b[A\n",
            "                                                                        \u001b[A2023-04-07 11:16:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.82 | nll_loss 7.779 | ppl 219.6 | bleu 1.18 | wps 1697.6 | wpb 2699.8 | bsz 96.8 | num_updates 4000 | best_bleu 1.18\n",
            "2023-04-07 11:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 4000 updates\n",
            "2023-04-07 11:16:11 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint_1_4000.pt\n",
            "2023-04-07 11:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint_1_4000.pt\n",
            "2023-04-07 11:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 1.18) (writing took 12.50844561599979 seconds)\n",
            "epoch 001:  11% 3446/32474 [30:41<3:47:08,  2.13it/s, loss=8.508, nll_loss=7.467, ppl=176.91, wps=7894.4, ups=2.08, wpb=3787.2, bsz=111.3, num_updates=4400, lr=0.000476731, gnorm=0.952, train_wall=47, gb_free=10.9, wall=0]"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
        "    data-bin/wmt16ende \\\n",
        "    --arch hc_transformer_wmt_en_de_small --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --max-epoch 30 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --save-interval-updates 10000 \\\n",
        "    --keep-last-epochs 3 \\\n",
        "    --patience 10 \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZo_BSh6SDmz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!fairseq-generate data-bin/wmt16ende \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --batch-size 128 --beam 5 --remove-bpe --quiet"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2ifsJ7YNZV8_"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
