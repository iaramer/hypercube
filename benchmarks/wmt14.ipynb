{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts, tokenizer):\n",
    "    res = tokenizer(\n",
    "        texts, \n",
    "        return_tensors=\"pt\",\n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "    return res['input_ids'], res['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None, n_step=100):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X).view(-1)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%n_step==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(device, model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            X = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "            output = model(X).view(-1)\n",
    "            loss = criterion(output, y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, model, iterator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(iterator)):\n",
    "            X = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "            output = model(X).view(-1)\n",
    "            y_pred += output.cpu().numpy().tolist()\n",
    "            y_true += y.cpu().numpy().tolist()\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len, embed_model_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.embed_dim = embed_model_dim\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.embed_dim)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.embed_dim)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Compute scale dot product attention\n",
    "\n",
    "    Query : given sentence that we focused on (decoder)\n",
    "    Key : every sentence to check relationship with Qeury(encoder)\n",
    "    Value : every sentence same with Key (encoder)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ScaleDotProductAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size, head, length, d_tensor = k.size()\n",
    "        k_t = k.transpose(2, 3)\n",
    "        score = (q @ k_t) / torch.sqrt(torch.tensor(d_tensor))\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -10000)\n",
    "        score = self.softmax(score)\n",
    "        v = score @ v\n",
    "        return v, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_heads = n_heads\n",
    "        self.attention = ScaleDotProductAttention()\n",
    "        self.w_q = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.w_k = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.w_v = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.w_concat = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "        out, attention = self.attention(q, k, v, mask=mask)\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "        return out\n",
    "\n",
    "    def split(self, tensor):\n",
    "        \"\"\"\n",
    "        split tensor by number of head\n",
    "\n",
    "        :param tensor: [batch_size, length, d_model]\n",
    "        :return: [batch_size, head, length, d_tensor]\n",
    "        \"\"\"\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "\n",
    "        d_tensor = d_model // self.n_heads\n",
    "        tensor = tensor.view(batch_size, length, self.n_heads, d_tensor).transpose(1, 2)\n",
    "        # it is similar to group convolution (split by number of heads)\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        \"\"\"\n",
    "        inverse function of self.split(tensor : torch.Tensor)\n",
    "\n",
    "        :param tensor: [batch_size, head, length, d_tensor]\n",
    "        :return: [batch_size, length, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads, drop_prob=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(input_size, hidden_size, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(input_size)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        _x = x\n",
    "\n",
    "        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm1(x + _x)\n",
    "        \n",
    "        _x = x\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "      \n",
    "        x = self.dropout(x)\n",
    "        x = self.norm2(x + _x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads, n_layers, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        encoder_layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layer = EncoderLayer(\n",
    "                input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                n_heads=n_heads,\n",
    "                drop_prob=drop_prob\n",
    "            )\n",
    "            encoder_layers.append(layer)\n",
    "        self.layers = nn.ModuleList(encoder_layers)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite\n",
    "class BinaryClassificationTransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken: int, model_size: int = 128, n_heads: int = 4, \n",
    "    nlayers: int = 1, dropout: float = 0.1, maxlen: int = 512):\n",
    "        super().__init__()\n",
    "        self.model_size = model_size\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEmbedding(maxlen, model_size)\n",
    "        self.emb = nn.Embedding(ntoken, model_size)\n",
    "        self.transformer_encoder = Encoder(\n",
    "            input_size=self.model_size, \n",
    "            hidden_size=self.model_size, \n",
    "            n_heads=n_heads, \n",
    "            n_layers=nlayers, \n",
    "            drop_prob=dropout\n",
    "        )\n",
    "        self.decoder = nn.Linear(model_size, 1)  # Bin classifier\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src = self.emb(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        pooled = output.mean(dim=1)\n",
    "        output = self.decoder(pooled)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypercube Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperCubeLayer(nn.Module):\n",
    "    __constants__ = ['in_features', 'out_sqrt_features']\n",
    "    in_features: int\n",
    "    out_sqrt_features: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_sqrt_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        hc_input_size = np.sqrt(in_features)\n",
    "        assert hc_input_size % 1 == 0\n",
    "        self.hc_input_size = hc_input_size = int(hc_input_size)\n",
    "        self.in_features = in_features\n",
    "        self.out_sqrt_features = out_sqrt_features  # No. of output features = out_sqrt_features * sqrt(in_features)\n",
    "        self.weight = nn.Parameter(torch.empty((out_sqrt_features, hc_input_size, hc_input_size), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty((out_sqrt_features,), **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, hc_input_size={}, out_sqrt_features={}, bias={}'.format(\n",
    "            self.in_features, self.hc_input_size, self.out_sqrt_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view((*x.shape[:-1], self.hc_input_size, self.hc_input_size))\n",
    "        x = (x.movedim(1,2) @ self.weight).movedim(2,1) + self.bias\n",
    "        x = x.flatten(start_dim=-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperCubeBlock(nn.Module):\n",
    "    def __init__(self, input_size, out_sqrt_features=None):\n",
    "        if out_sqrt_features is None:\n",
    "            out_sqrt_features = input_size\n",
    "        super(HyperCubeBlock, self).__init__()\n",
    "        self.hc_layers_1 = HyperCubeLayer(input_size, int(np.sqrt(input_size)))  # TODO: fix\n",
    "        self.hc_layers_2 = HyperCubeLayer(input_size, out_sqrt_features)\n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.hc_layers_1(x)\n",
    "        # !Check if needed\n",
    "        # sq = int(np.sqrt(x.shape[-1]))\n",
    "        # x = x.view((*x.shape[:-1], sq, sq))\n",
    "        # x = x.transpose(-1,-2)\n",
    "        # x = x.flatten(start_dim=-2)\n",
    "        x = self.relu(x)\n",
    "        x = self.hc_layers_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionHC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads):\n",
    "        super(MultiHeadAttentionHC, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_heads = n_heads\n",
    "        self.attention = ScaleDotProductAttention()\n",
    "        self.hidden_size = self.input_size  # TMP second param is also input_size instead of hidden_size\n",
    "        # self.w_q = HyperCubeBlock(self.input_size, self.hidden_size)\n",
    "        # self.w_k = HyperCubeBlock(self.input_size, self.hidden_size)\n",
    "        # self.w_v = HyperCubeBlock(self.input_size, self.hidden_size)\n",
    "        self.w_q = HyperCubeBlock(self.input_size, int(np.sqrt(self.hidden_size)))\n",
    "        self.w_k = HyperCubeBlock(self.input_size, int(np.sqrt(self.hidden_size)))\n",
    "        self.w_v = HyperCubeBlock(self.input_size, int(np.sqrt(self.hidden_size)))\n",
    "        self.w_concat = HyperCubeBlock(self.hidden_size, int(np.sqrt(self.hidden_size)))\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "        out, attention = self.attention(q, k, v, mask=mask)\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "        return out\n",
    "\n",
    "    def split(self, tensor):\n",
    "        \"\"\"\n",
    "        split tensor by number of head\n",
    "\n",
    "        :param tensor: [batch_size, length, d_model]\n",
    "        :return: [batch_size, head, length, d_tensor]\n",
    "        \"\"\"\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "\n",
    "        d_tensor = d_model // self.n_heads\n",
    "        tensor = tensor.view(batch_size, length, self.n_heads, d_tensor).transpose(1, 2)\n",
    "        # it is similar with group convolution (split by number of heads)\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        \"\"\"\n",
    "        inverse function of self.split(tensor : torch.Tensor)\n",
    "\n",
    "        :param tensor: [batch_size, head, length, d_tensor]\n",
    "        :return: [batch_size, length, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayerHC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads, drop_prob=0.1):\n",
    "        super(EncoderLayerHC, self).__init__()\n",
    "        self.attention = MultiHeadAttentionHC(input_size, hidden_size, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        hidden_size = input_size  # TMP second param is also input_size instead of hidden_size\n",
    "        # self.linear1 = HyperCubeBlock(input_size, hidden_size)\n",
    "        # self.linear2 = HyperCubeBlock(hidden_size, input_size)\n",
    "        self.linear1 = HyperCubeBlock(input_size, int(np.sqrt(hidden_size)))\n",
    "        self.linear2 = HyperCubeBlock(hidden_size, int(np.sqrt(input_size)))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(input_size)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        _x = x\n",
    "\n",
    "        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.norm1(x + _x)\n",
    "        _x = x\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.norm2(x + _x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderHC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads, n_layers, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        encoder_layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layer = EncoderLayerHC(\n",
    "                input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                n_heads=n_heads,\n",
    "                drop_prob=drop_prob\n",
    "            )\n",
    "            encoder_layers.append(layer)\n",
    "        self.layers = nn.ModuleList(encoder_layers)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EncoderLayerHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wmt14/de-en to C:/Users/yaram/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 658M/658M [01:32<00:00, 7.14MB/s]\n",
      "Downloading data: 100%|██████████| 919M/919M [02:07<00:00, 7.19MB/s]]\n",
      "Downloading data: 100%|██████████| 80.5M/80.5M [00:11<00:00, 6.76MB/s]\n",
      "Downloading data: 100%|██████████| 38.7M/38.7M [00:05<00:00, 7.37MB/s]\n",
      "Downloading data files: 100%|██████████| 5/5 [04:02<00:00, 48.44s/it]\n",
      "Extracting data files: 100%|██████████| 5/5 [00:33<00:00,  6.76s/it]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wmt14 downloaded and prepared to C:/Users/yaram/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.33it/s]\n"
     ]
    }
   ],
   "source": [
    "WMT14_DATASET = load_dataset('wmt14', 'de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 4508785\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3003\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMT14_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode',\n",
       "  'en': 'Resumption of the session'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMT14_DATASET['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\core\\frame.py:745\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 745\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    746\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    747\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    748\u001b[0m         data,\n\u001b[0;32m    749\u001b[0m         columns,\n\u001b[0;32m    750\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    751\u001b[0m         dtype,\n\u001b[0;32m    752\u001b[0m     )\n\u001b[0;32m    753\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    754\u001b[0m         arrays,\n\u001b[0;32m    755\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    758\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    759\u001b[0m     )\n\u001b[0;32m    760\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\core\\internals\\construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\core\\internals\\construction.py:867\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    865\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    866\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], abc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m--> 867\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m    869\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\core\\internals\\construction.py:947\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    945\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    946\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[1;32m--> 947\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39;49msort)\n\u001b[0;32m    948\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(pre_cols)\n\u001b[0;32m    950\u001b[0m \u001b[39m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[39m# classes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\_libs\\lib.pyx:416\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\pandas\\core\\internals\\construction.py:945\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[39mcolumns : Index\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 945\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39;49mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    946\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    947\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39msort)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.DataFrame(WMT14_DATASET['train']['translation'])\n",
    "df_val = pd.DataFrame(WMT14_DATASET['validation']['translation'])\n",
    "df_test = pd.DataFrame(WMT14_DATASET['test']['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember u...</td>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie Sie feststellen konnten, ist der gefürchte...</td>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heute möchte ich Sie bitten - das ist auch der...</td>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508780</th>\n",
       "      <td>Das bleibt eine der größten Errungenschaften i...</td>\n",
       "      <td>Their achievement remains one of the greatest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508781</th>\n",
       "      <td>Gleichzeitig scheint sich Zumas revolutionäre ...</td>\n",
       "      <td>At the same time, Zuma’s revolutionary generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508782</th>\n",
       "      <td>In einer Region, wo die älteren Menschen sehr ...</td>\n",
       "      <td>In a region that reveres the elderly, Zuma’s a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508783</th>\n",
       "      <td>Drei von zehn Südafrikanern sind jünger als 15...</td>\n",
       "      <td>Three in ten South Africans are younger than 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508784</th>\n",
       "      <td>Irgendwie muss Zuma einen Weg finden, einersei...</td>\n",
       "      <td>Somehow Zuma must find a way to honor his own ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4508785 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        de  \\\n",
       "0                       Wiederaufnahme der Sitzungsperiode   \n",
       "1        Ich erkläre die am Freitag, dem 17. Dezember u...   \n",
       "2        Wie Sie feststellen konnten, ist der gefürchte...   \n",
       "3        Im Parlament besteht der Wunsch nach einer Aus...   \n",
       "4        Heute möchte ich Sie bitten - das ist auch der...   \n",
       "...                                                    ...   \n",
       "4508780  Das bleibt eine der größten Errungenschaften i...   \n",
       "4508781  Gleichzeitig scheint sich Zumas revolutionäre ...   \n",
       "4508782  In einer Region, wo die älteren Menschen sehr ...   \n",
       "4508783  Drei von zehn Südafrikanern sind jünger als 15...   \n",
       "4508784  Irgendwie muss Zuma einen Weg finden, einersei...   \n",
       "\n",
       "                                                        en  \n",
       "0                                Resumption of the session  \n",
       "1        I declare resumed the session of the European ...  \n",
       "2        Although, as you will have seen, the dreaded '...  \n",
       "3        You have requested a debate on this subject in...  \n",
       "4        In the meantime, I should like to observe a mi...  \n",
       "...                                                    ...  \n",
       "4508780  Their achievement remains one of the greatest ...  \n",
       "4508781  At the same time, Zuma’s revolutionary generat...  \n",
       "4508782  In a region that reveres the elderly, Zuma’s a...  \n",
       "4508783  Three in ten South Africans are younger than 1...  \n",
       "4508784  Somehow Zuma must find a way to honor his own ...  \n",
       "\n",
       "[4508785 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train[\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df_train['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_en_input_train = tokenize(df_train['en'])\n",
    "tokenized_en_input_val = tokenize(df_val['en'])\n",
    "tokenized_en_input_test = tokenize(df_test['en'])\n",
    "\n",
    "tokenized_de_output_train = tokenize(df_train['de'])\n",
    "tokenized_de_output_val = tokenize(df_val['de'])\n",
    "tokenized_de_output_test = tokenize(df_test['de'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m TensorDataset(WMT14_DATASET[\u001b[39m'\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtranslation\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\torch\\utils\\data\\dataset.py:189\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39;49m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39;49m tensor\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m tensor \u001b[39min\u001b[39;49;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "File \u001b[1;32mc:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\torch\\utils\\data\\dataset.py:189\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "TensorDataset(WMT14_DATASET['validation']['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "        tokenized_ru_input_train,\n",
    "        tokenized_en_output_train\n",
    "    )\n",
    "val_dataset = TensorDataset(\n",
    "        tokenized_ru_input_val,\n",
    "        tokenized_en_output_val\n",
    "    )\n",
    "test_dataset = TensorDataset(\n",
    "        tokenized_ru_input_test,\n",
    "        tokenized_en_output_test\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 27.8kB/s]\n",
      "c:\\Users\\yaram\\miniconda3\\envs\\pytorch_1\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yaram\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 721kB/s] \n",
      "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 1.04MB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 528kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train_inputs, df_train_mask = tokenize(list(df_train['text']), tokenizer)\n",
    "df_val_inputs, df_val_mask = tokenize(list(df_val['text']), tokenizer)\n",
    "df_test_inputs, df_test_mask = tokenize(list(df_test['text']), tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix for without labelling\n",
    "%%time\n",
    "\n",
    "# convert the data to torch tensors\n",
    "# train_labels = torch.tensor(df_train['label'].to_numpy(), dtype=torch.float32)\n",
    "# valid_labels = torch.tensor(df_val['label'].to_numpy(), dtype=torch.float32)\n",
    "# test_labels = torch.tensor(df_test['label'].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "# create TensorDataset\n",
    "train_dataset = TensorDataset(df_train_inputs, train_labels)\n",
    "valid_dataset = TensorDataset(df_val_inputs, valid_labels)\n",
    "test_dataset = TensorDataset(df_test_inputs, test_labels)\n",
    "\n",
    "# create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "loaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": valid_dataloader,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_lab_1k",
   "language": "python",
   "name": "nlp_lab_1k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
